

=== PAGE 1 ===
Repulsive Curves CHRIS YU,   Carnegie Mellon University HENRIK SCHUMACHER,   RWTH Aachen University KEENAN CRANE,   Carnegie Mellon University Fig. 1. We develop an efficient strategy for optimizing curves while avoiding self-collisions. Here for instance, interwoven curves of increasing length are confined inside a fixed domain, resulting in an intricate ‚Äúcurve packing.‚Äù Replacing ordinary gradient descent with a specially-tailored   fractional Sobolev gradient   lets us take very large steps toward the solution, enabling rapid design exploration. Curves play a fundamental role across computer graphics, physical sim- ulation, and mathematical visualization, yet most tools for curve design do nothing to prevent crossings or self-intersections. This paper develops efficient algorithms for (self-)repulsion of plane and space curves that are well-suited to problems in computational design. Our starting point is the so-called   tangent-point energy , which provides an infinite barrier to self- intersection. In contrast to local collision detection strategies used in,   e.g. , physical simulation, this energy considers interactions between all pairs of points, and is hence useful for global shape optimization: local minima tend to be aesthetically pleasing, physically valid, and nicely distributed in space. A reformulation of gradient descent, based on a   Sobolev-Slobodeckij inner product   enables us to make rapid progress toward local minima‚Äîindependent of curve resolution. We also develop a hierarchical multigrid scheme that significantly reduces the per-step cost of optimization. The energy is easily integrated with a variety of constraints and penalties ( e.g. , inextensibility, or obstacle avoidance), which we use for applications including curve packing, knot untangling, graph embedding, non-crossing spline interpolation, flow visualization, and robotic path planning. CCS Concepts:   ‚Ä¢   Computing methodologies   ‚Üí   Shape modeling ; ‚Ä¢   Mathematics of computing   ‚Üí   Continuous optimization . Additional Key Words and Phrases:   Computational design, shape opti- mization, curves, knots Authors‚Äô addresses: Chris Yu, Carnegie Mellon University; Henrik Schumacher, RWTH Aachen University, Templergraben 55, Aachen, Germany, 52062; Keenan Crane, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, PA, 15213. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. ¬©   XXXX Association for Computing Machinery. 0730-0301/XXXX/-1-ARTXX $15.00 https://doi.org/XX 1   INTRODUCTION Shape optimization plays a role in a broad range of tasks ranging from variational data fitting to computational design. However, for many tasks it is essential to design   in context ,   i.e. , relative to the ge- ometry of the surrounding environment. Hard boundary conditions ( e.g. , fixing the endpoints of a cable) provide a basic mechanism for providing context, but do not account for another fundamental requirement: physical objects cannot penetrate solid objects in the environment, nor can they intersect themselves. In some contexts, self-intersection can be avoided by detecting and resolving colli- sions at the moment of impact. However, forward simulation is not particularly effective at guiding shape optimization toward an intelligent design‚Äîfor example, untangling a complicated knot via forward physical simulation is just as hard as trying to untangle it by hand. In this paper we instead explore how a global variational approach to curve self-avoidance provides new opportunities for computational design. Our starting point is the   tangent-point en- ergy   of Buck and Orloff [1995], which for an arc-length parameterized curve   Œ≥   :   M   ‚Üí   R 3 can be expressed as an integral over all pairs of points   ( x ,   y ) ‚àà   M 2   : =   M   √ó   M : ‚Ñ∞   : = ‚à¨ M   2 1 r   ( Œ≥   ( x ) ,   Œ≥   ( y )) Œ±   dxd y .   (1) Here   r   ( x ,   y )   is the radius of the smallest sphere tangent to   Œ≥   ( x )   and passing through   Œ≥   ( y ) , and   Œ±   ‚àà   R   is a parameter controlling the strength of repulsion. This energy ap- proaches infinity for points   Œ≥   ( y )   that are close to   Œ≥   ( x )   in space but far from   Œ≥   ( x )   along the curve itself‚Äîpreventing self-collision. For points   Œ≥   ( y ‚Ä≤ )   close to   Œ≥   ( x )   along   the curve, the radius   r   is very large‚Äî keeping forces bounded, and making the integral well-defined. ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 2 ===
XX:2   ‚Ä¢   Yu, Schumacher, and Crane Although this energy has a simple definition, its gradient involves high-order   fractional   derivatives. Hence, classic optimization tech- niques must take extremely small steps, and standard techniques from shape optimization are not well-suited to handle the nonlocal nature of the energy. Our approach is to develop a preconditioner that   exactly   matches the fractional order of the differential (Sec- tion 4). In doing so, we obtain a gradient descent equation involving no spatial derivatives, permitting large time steps that make rapid progress toward local minima (Figure 2). In practice, this method is orders of magnitude more efficient than the simple untangling schemes often used in the knot literature (Figure 15), and offers substantial improvements over general-purpose optimization tech- niques from geometry processing (Section 7). Algorithms of this fla- vor have proven effective for problems such as finding minimal sur- faces [Pinkall and Polthier 1993], integrating Willmore flow [Schu- macher 2017], and computing surface parameterizations [Kovalsky et al   .   2016]. However, little work has been done in the more chal- lenging setting of nonlocal, ‚Äúall-pairs‚Äù energies. Contributions.   Though knot energies have received significant attention in mathematics, there has been little work on the numer- ical and algorithmic tools needed to apply such energies to the computational design of curves. In this paper we develop: ‚Ä¢   a principled discretization of the tangent-point energy, ‚Ä¢   a novel preconditioner based on the   Sobolev-Slobodeckij   inner product, ‚Ä¢   a numerical solver that easily incorporates constraints needed for design, and ‚Ä¢   a Barnes-Hut strategy and hierarchical multigrid scheme for the tangent-point energy that greatly improve scalability. We also explore a collection of constraints and potentials that en- able us to apply this machinery to a broad range of applications in visualization and computational design (Section 8). 2   RELATED WORK We briefly review topics related to computational design of curves; Section 3 gives more detailed background on curve energies. At a high level, computational design of free-form curves has generally focused on specific domains such as road networks [Hassan et al   . 1998; McCrae and Singh 2009], telescoping structures [Yu et al   .   2017], or rod assemblies [P√©rez et al   .   2015; Zehnder et al   .   2016]; Moreton [1992, Chapter 3] gives a history of traditional design via spline curves. Our goal is to develop tools that can be applied to a wide range of multi-objective design scenarios, as explored in Section 8. 2.1   Curve Simulation One natural idea is to avoid collision via physics-based simulation of elastic rods [Bergou et al   .   2008]. However, the paradigm of collision detection and response is ‚Äútoo local‚Äù: for computational design, one aims to globally optimize a variety of design criteria, rather than simulate the behavior of a given curve.   Sensitivity analysis , which provides sophisticated   local   improvement of an initial design, has been successfully applied to several rod design problems [P√©rez et al   . 2015; Zehnder et al   .   2016; P√©rez et al   .   2017]. This technique can be seen as complementary to global repulsion-based form-finding, helping to incorporate,   e.g. , nonlinear mechanical phenomena into Fig. 2. Untangling the   Freedman unknot (top left)   to the unit circle. For the same wall clock time, standard   L 2   gradient descent makes almost no progress, whereas conventional Sobolev descent fails to smooth out low ( H   1 )   or high   ( H   2 )   frequencies. By carefully matching the inner product to the energy, our fractional   H   s   descent quickly flows to the circle. a final design. Curves also arise naturally as filaments or field lines in continuum phenomena like fluids, plasmas, and superfluids [An- gelidis and Neyret 2005; Wei√ümann and Pinkall 2010; Padilla et al   . 2019; Kleckner et al   .   2016; Chern et al   .   2016; DeForest and Kankel- borg 2007]. However, using such phenomena for curve design is challenging since (i) initial conditions are hard to construct, and (ii) these systems naturally exhibit   reconnection events   where distinct pieces of a curve merge [Maucher and Sutcliffe 2016]. 2.2   Knot Energies Motivated by questions in mathematics, biology, and physics [Calvo et al .   2002], there is a significant body of work on the   unknot problem : can a closed loop be continuously deformed into a circle without passing through itself ( i.e. , via   isotopy )? Solving this decision prob- lem is not our goal‚Äîso far it is not clear it can even be done in polynomial time [Lackenby 2014]. Yet knot untangling energies (discussed in Section 3) provide a valuable starting point for com- putational design. Numerically, simple ad-hoc methods that repel all pairs of vertices can yield inconsistent, unreliable behavior and slow convergence (Figure 15,   right ). Starting with more principled discretizations,   KnotPlot   [Scharein 1998] uses a simple relaxation scheme, and Kusner and Sullivan [1998] apply a standard conjugate gradient method via   SurfaceEvolver   [Brakke 1992], both evaluat- ing all   O ( n 2 )   interactions between the   n   vertices. Other, adjacent methods have been developed for   tightening   a given knot [Piera≈Ñski 1998; Ashton et al .   2011], simulating the knot tying process [Brown et al   .   2004; Kubiak et al .   2007; Harmon et al .   2009], or untangling knots without optimizing their shape [Ladd and Kavraki 2004]; more recent methods apply   L 2   [Walker 2016] or integer Sobolev ( H   2 ) descent [Bartels et al   .   2018]. Octrees have been used to evaluate the ropelength of a static knot [Ashton and Cantarella 2005], but Barnes-Hut/multipole schemes have not yet been developed for energy minimization. Likewise, little has been said about fractional preconditioners, and treatment of general constraints. Our approach builds on careful analysis of the fractional Sobolev spaces associated with the tangent point energy [Blatt 2012, 2013; Blatt and Reiter 2015]. Whereas this work focuses on,   e.g. , the exis- tence of local minimizers and short-time existence of gradient flows in the smooth setting, we use it to develop numerical algorithms. ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 3 ===
Repulsive Curves   ‚Ä¢   XX:3 2.3   Geometric Optimization Optimization of curve and surface energies can be greatly acceler- ated by ‚ÄúSobolev-like‚Äù preconditioning. The idea is to replace the usual   L 2   inner product with one better matched to the energy‚Äî Section 4.1 gives a didactic example. Such flows make more rapid progress toward minimizers (Figure 2), since energy is reduced uniformly across all spatial frequencies. Crucially, Sobolev precon- ditioners are most effective when the   order of the preconditioner is perfectly matched to the order of spatial derivatives in the energy . A preconditioner whose order is too high or too low can slow down convergence‚Äîsee for instance Figure 5,   bottom-right . Sobolev-type preconditioners have seen some prior use in geom- etry processing and scientific computing. For example, the minimal surface algorithm of Pinkall and Polthier [1993] effectively performs Sobolev descent [Brakke 1994, Section 16.10], but was not originally framed in these terms; Renka and Neuberger [1995] give an algo- rithm directly formulated via a (variable) Sobolev inner product. Later work adopts Sobolev-like strategies for surface fairing and filtering [Desbrun et al   .   1999; Eckstein et al   .   2007; Martin et al   .   2013; Crane et al   .   2013; Schumacher 2017]. More recently, Sobolev-like descent has become popular for minimizing elastic energies, such as those arising in surface parameterization or shape deformation [Ko- valsky et al   .   2016; Claici et al   .   2017; Zhu et al   .   2018]; see Section 7 for in-depth comparisons. Importantly, previous work on shape optimization does not con- sider the challenging   fractional   case, which differs significantly from standard Sobolev preconditioning. From an analytical point of view, one must do work even to determine the order of derivatives arising in the differential, which we do by reasoning about the associated function spaces (Appendix A). We use this knowledge to formulate a novel preconditioner in the smooth setting which carefully con- siders lower-order terms (Section 4), which we then translate into the discrete setting via a principled discretization of the tangent- point energy (Section 5). From a computational point of view, the machinery needed to apply a fractional preconditioner is also dif- ferent from ordinary Sobolev preconditioners: one cannot simply solve a sparse linear system, but must instead construct an efficient hierarchical scheme for (approximately) inverting a dense nonlocal operator. None of these pieces appear in the previous optimization work discussed above, though the combination of fractional oper- ators and multigrid methods has been studied in other contexts, such as finite element simulation [Ainsworth and Glusa 2017] and multiphysics systems [B√¶rland et al   .   2019; B√¶rland 2019]. Further, previously studied Sobolev preconditioners (such as those based on the Laplacian) and standard optimization strategies (such as New- ton descent) are not as effective for our problem‚Äîas we show via extensive numerical experiments (Section 7). 3   CURVE ENERGIES We first give a detailed discussion of the tangent-point energy, which we optimize in Section 4. Throughout we will use single bars   | X   |   and brackets   ‚ü® X ,   Y   ‚ü©   to denote the Euclidean inner product on vectors in   R 3 , and reserve double bars   ‚à•   f   ‚à•   and brackets   ‚ü®‚ü® f   ,   –¥ ‚ü©‚ü©   for norms and inner products on functions. We also use   ¬∑| f   to indicate that a quantity ( e.g. , an energy) is evaluated at a function   f   . 3.1   Background Consider a collection of curves given by a parameterization   Œ≥   :   M   ‚Üí R 3 , where   M   is comprised of intervals and/or loops. How can we formulate an energy that prevents self-intersection of   Œ≥   ? In general we will consider energies of the form ‚Ñ∞ ( Œ≥   )   = ‚à¨ M   2 k ( x ,   y )   dx Œ≥   d y Œ≥   , where the kernel   k   :   M   √ó   M   ‚Üí   R   captures the interaction between two points on the curve, and   dx Œ≥   denotes the length element on   Œ≥   . 3.1.1   Electrostatic Potential.   One natural idea for defining   k   is to imagine that there is electric charge distributed along   Œ≥   that pushes it away from itself, producing the Coulomb-like potential k Coulomb ( x ,   y )   : =   1 | Œ≥   ( x )‚àí Œ≥   ( y )| Œ±   ,   (2) where the parameter   Œ±   controls the strength of re- pulsion. Unfortunately this simple energy does not work for a continuous curve: for   Œ±   <   2   it is not strong enough to prevent collisions, allowing the curve to pass through itself‚Äîyet for   Œ±   ‚â•   1   the inte- gral does not exist, resulting in unpredictable and unreliable behavior when discretized. 3.1.2   M√∂bius Energy.   To get a well-defined energy, one can   regular- ize   the integrand in regions where   x   approaches   y . One possibility, proposed by O‚ÄôHara [1991], is the   M√∂bius energy , with kernel k M√∂bius ( x ,   y )   : =   1 | Œ≥   ( x )‚àí Œ≥   ( y )| 2   ‚àí   1 d ( x ,   y ) 2   , where   d ( x ,   y )   denotes the shortest distance between   x   and   y   along the curve ( e.g. , the smaller of two arcs along a circle). Intuitively: if two points are both close in space and close along the curve, we remove the singular energy; if they are close in space but   distant along the curve, they continue to repel each other (see inset). This energy is invariant to M√∂bius transformations [Freedman et al   .   1994], which can be attractive from the perspective of knot theory‚Äîbut causes problems for computational design, since near-intersections may not be penalized in a natural way (Figure 3). M√∂bius   Tangent-Point Fig. 3.   Left:   Since the M√∂bius energy is scale-invariant, it allows ‚Äútight spots‚Äù where the curve nearly touches itself; such features are avoided by the tangent-point energy.   Right:   The M√∂bius energy can likewise artificially eliminate knots by pulling them tight at no energetic cost. (Leftmost image from Kusner and Sullivan [1998].) ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 4 ===
XX:4   ‚Ä¢   Yu, Schumacher, and Crane Fig. 4. Local minimizers of the tangent-point energy   ‚Ñ∞ Œ± 2 Œ±   . When   Œ±   =   2   the tangent-point energy is scale-invariant and can exhibit ‚Äútight spots‚Äù; for larger values of   Œ±   local interactions are penalized more than distant ones. 3.2   Tangent Point Energy Instead, we will use the tangent point energy introduced in Section 1. We can write this energy more explicitly by noting that (up to a constant factor) r   ( x ,   y )   =   | Œ≥   ( x )‚àí Œ≥   ( y )| 2 | T   ( x ) √ó ( Œ≥   ( x )‚àí Œ≥   ( y ))| where   T   ( x )   is the unit tangent of   Œ≥   at   x . This expression leads to a generalized tangent-point energy [Blatt and Reiter 2015], given by ‚Ñ∞ Œ± Œ≤   ( Œ≥   )   : = ‚à¨ M   2 k Œ± Œ≤   ( Œ≥   ( x ) ,   Œ≥   ( y ) , T   ( x ))   dx Œ≥   d y Œ≥   , where   k Œ± Œ≤   is the   tangent-point kernel k Œ± Œ≤   ( p ,   q , T   )   : =   | T   √ó ( p   ‚àí   q )| Œ± | p   ‚àí   q | Œ≤   .   (3) In the case   Œ≤   =   2 Œ± , this energy agrees with Equation 1; as shown by Blatt [2013] it is well-defined for any   Œ± ,   Œ≤   satisfying   Œ±   >   1   and Œ≤   ‚àà [ Œ±   +   2 ,   2 Œ±   +   1 )   (Lemma A.1). Most importantly, it tends toward infinity as the curve approaches itself, preventing self-intersection. In particular, when   Œ≤   ‚àí   Œ±   >   2   it is not scale-invariant, and hence avoids the pull-tight phenomenon. (We set   ( Œ± ,   Œ≤ )   to   ( 2 ,   4 . 5 )   in Figures 14‚Äì19, and   ( 3 ,   6 )   elsewhere.) This energy is also attractive for design since it provides natu- ral regularization, akin to bending energy. The reason is that the integrand can vanish only for a straight line (where the radius   r   is infinite at every point). The powers   Œ≤   and   Œ±   have an impact on this bending behavior‚Äîfor instance, if   Œ≤   =   2 Œ± , then a higher   Œ±   gives a more repulsive energy where curves are willing to bend more in order to avoid collision (Figure 4). 4   OPTIMIZATION Consider an energy   ‚Ñ∞   that depends on a function   f   . A typical start- ing point for optimization is to integrate the gradient flow d dt   f   =   ‚àí   grad   ‚Ñ∞ ( f   ) ,   (4) i.e. , to move in the direction of ‚Äústeepest descent.‚Äù As mentioned in Section 2, however, the efficiency of this flow depends critically on the   inner product   used to define the gradient‚Äîin other words, there are many different notions of what it means to be ‚Äústeepest.‚Äù Recall in particular that the   differential   d ‚Ñ∞   describes the change in   ‚Ñ∞   due to any small perturbation   u   of   f   : d ‚Ñ∞   | f   ( u )   =   lim Œµ   ‚Üí 0 1 Œµ   ( ‚Ñ∞ ( f   +   Œµ u ) ‚àí   ‚Ñ∞ ( f   ))   . The   gradient   of   ‚Ñ∞   is then the unique function   grad   ‚Ñ∞   whose inner product with any function   u   gives the differential in that direction: ‚ü®‚ü® grad   ‚Ñ∞ ,   u ‚ü©‚ü© V   =   d ‚Ñ∞ ( u ) .   (5) Traditionally, the inner product   ‚ü®‚ü®¬∑ ,   ¬∑‚ü©‚ü© V   is just the   L 2   inner product ‚ü®‚ü® u ,   v ‚ü©‚ü© L 2   : =   ‚à´ M   ‚ü® u ( x ) ,   v ( x )‚ü©   dx   . More generally, however, one can try to pick a so-called   Sobolev inner product   ‚ü®‚ü® u ,   v ‚ü©‚ü© H   k   that yields an easier gradient flow equation. Examples include the   H   1   and   H   2   inner products, which for a domain without boundary can be written as ‚ü®‚ü® u ,   v ‚ü©‚ü© H   1   : =   ‚ü®‚ü® grad   u ,   grad v ‚ü©‚ü© L 2   =   ‚àí‚ü®‚ü® ‚àÜ u ,   v ‚ü©‚ü© L 2   ,   (6) and ‚ü®‚ü® u ,   v ‚ü©‚ü© H   2   : =   ‚ü®‚ü® ‚àÜ u ,   ‚àÜ v ‚ü©‚ü© L 2   =   ‚ü®‚ü® ‚àÜ 2 u ,   v ‚ü©‚ü© L 2   ,   (7) which measure first and second derivatives ( resp. ) rather than func- tion values. In general, if we write our inner product as   ‚ü®‚ü® u ,   v ‚ü©‚ü© H   k   = ‚ü®‚ü® Au ,   v ‚ü©‚ü© L 2   for some linear operator   A , then we can express the new gradient direction   –¥   as the solution to A –¥   =   grad L 2   ‚Ñ∞   .   (8) This transformation is akin to the preconditioning provided by New- ton‚Äôs method, except that we replace the Hessian with an operator A   that is always positive-definite, and often easier to invert. In particular, when   A   comes from a carefully-designed Sobolev inner product, it will eliminate spatial derivatives, avoiding the stringent time step restriction typically associated with numerical integration of gradient flow (Figure 6). 4.1   Warm-up: Dirichlet energy Since analysis of the tangent-point energy is quite involved, we begin with a standard ‚Äútoy‚Äù example that helps sketch out the main ideas of our approach. In particular, consider the   Dirichlet energy ‚Ñ∞ D   ( f   )   : =   1 2 ‚à´ Œ©   |   grad   f   ( x )| 2   dx ,   (9) standard gradient descent ( L 2 )   mismatched Sobolev descent ( H 2   ) well-matched Sobolev descent ( H 1 ) Fig. 5. For Dirichlet energy, which penalizes variations in a function   f   ( x   ) , standard   L 2   gradient descent mostly smooths out local features   (bottom left) , whereas an inner product that is too high-order has trouble removing high frequencies   (bottom right) . A Sobolev descent that is well-matched to the order of the energy yields rapid progress toward a local minimizer   (top) . We apply a similar strategy to quickly optimize the shape of curves. ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 5 ===
Repulsive Curves   ‚Ä¢   XX:5 which penalizes variation in a function   f   :   Œ©   ‚Üí   R . If the domain   Œ© has no boundary, then we can use integration by parts to write this energy as ‚Ñ∞ D   ( f   )   =   1 2   ‚ü®‚ü® grad   f   ,   grad   f   ‚ü©‚ü© L 2   =   ‚àí   1 2   ‚ü®‚ü® ‚àÜ f   ,   f   ‚ü©‚ü© L 2   , where   ‚àÜ   denotes the Laplace operator. The differential is then d ‚Ñ∞ D   | f   ( u )   =   ‚àí‚ü®‚ü® ‚àÜ f   ,   u ‚ü©‚ü© L 2   , and from Equation 5, we see that the   L 2   gradient of   ‚Ñ∞ D   is given by grad L 2   ‚Ñ∞ D   | f   =   ‚àí ‚àÜ f   . Hence,   L 2   gradient descent yields the   heat flow d dt   f   =   ‚àÜ f   ,   ( L 2   gradient flow) which involves second-order derivatives in space [Andrews et al   . 2020, Section 1.2]. If we try to solve this equation using, say, explicit finite differences with grid spacing   h , we will need a time step of size O ( h 2 )   to remain stable‚Äîsignificantly slowing down computation as the grid is refined. To lift this time step restriction, we can use a different inner product to define the gradient. In particular, replacing ‚ü®‚ü®¬∑ ,   ¬∑‚ü©‚ü© V   with the   H   1   inner product in Equation 5 yields ‚ü®‚ü® ‚àÜ   grad H   1   ‚Ñ∞ D   ,   u ‚ü©‚ü© L 2   =   ‚ü®‚ü® ‚àÜ f   ,   u ‚ü©‚ü© L 2   .   (10) This equation can be satisfied by letting   grad H   1   ‚Ñ∞ D   : =   f   , in which case Equation 4 defines an   H   1   gradient flow d dt   f   =   ‚àí f   .   ( H   1   gradient flow) Fig. 6. Gradient flows projected onto a low- and high-frequency mode e 1 ,   e 2 ,   resp.   Notice that poor precon- ditioning leads to slow convergence. This flow involves no spatial derivatives, and hence comes with no time step restriction. In effect, rather than a PDE, we now have a system of indepen- dent ODEs, which is far eas- ier to integrate numerically. As shown in Figure 5, the charac- ter of this flow is quite different: it makes progress by simultane- ously flattening all spatial fre- quencies, rather than just per- forming local smoothing. While this approach is not appropri- ate for dynamical simulation, it is quite useful for finding local minima, as needed in geometric design. In general, however, Sobolev descent is not as simple as just uniform scaling‚Äîinstead, one must solve a linear PDE (Equation 8) for the new descent direction. Note that we should not use an inner product with   too many derivatives. For example, if we use the   H   2   inner product (Equation 7) we get a gradient   grad H   2   ‚Ñ∞ D   | f   =   ‚àí ‚àÜ ‚àí 1   f   , and a flow d dt   f   =   ‚àÜ ‚àí 1   f   .   ( H   2   gradient flow) This flow is again hard to integrate, and has trouble smoothing out high frequencies (Figure 5,   bottom-right ). In general, one cannot achieve good behavior by blindly picking a Sobolev inner product, but must instead   carefully match the inner product to the energy . Low-Order Terms.   One remaining issue is that Equation 10 de- termines the   H   1   gradient only up to functions in the null space of ‚àÜ . This situation is problematic, since it means we cannot obtain a gradient by solving Equation 8 directly (with   A   =   ‚àí ‚àÜ ). Instead, we must include   low-order terms   that make the overall operator   A invertible. For instance, we could let   A   : =   ‚àí ‚àÜ   +   id , where   id   denotes the identity. But if we uniformly scale the domain by a factor   c   >   0 , the new operator looks like   ‚àí   1 c 2   ‚àÜ   +   id   and the character of the flow changes substantially: when   c   is small it looks like the   H   1   flow; when   c   is large, it looks more like the   L 2   flow. Careful treatment of regularization and scaling is therefore an important consideration in the development of our curve flow (Section 4.2.3). 4.2   Fractional Sobolev Gradient In the case of a nonlocal energy like the tangent-point energy   ‚Ñ∞ Œ± Œ≤   , one can no longer use a standard Sobolev inner product‚Äîinstead, an inner product of   fractional   order is needed, in order to match fractional derivatives that appear in the differential. Construction of a suitable inner product for the tangent-point energy is fairly technical‚Äîin a nutshell, we begin with a known expression for the   fractional Laplacian   on Euclidean   R n   , and formulate an anal- ogous operator for embedded curves. Taking additional (integer) derivatives yields a differential operator   B œÉ   of the same order as the differential   d ‚Ñ∞ Œ± Œ≤   . We then add a lower-order operator   B 0 œÉ   that makes the overall operator   A œÉ   : =   B œÉ   +   B 0 œÉ   more well-behaved. Our Sobolev-Slobodeckij inner product   is then defined as ‚ü®‚ü® u ,   v ‚ü©‚ü© H   s Œ≥   : =   ‚ü®‚ü® A œÉ   u ,   v ‚ü©‚ü© L 2   . Details are given in Appendix A‚Äîhere we give only the most essen- tial definitions needed to derive our discrete algorithm (Section 5). 4.2.1   Derivative Operator.   To define the inner product, we will need the first derivative operator   ùíü   given by ùíü u   : =   du d Œ≥   T /| d Œ≥   | 2 .   (11) This operator just takes the usual derivative of   u   along   M   and ex- presses it as a vector in   R 3   tangent to   Œ≥   ; the factor   1 /| d Œ≥   | 2   accounts for the fact that the curve is not in general arc-length parameterized. 4.2.2   High-Order Term.   As discussed in Appendix A.3, the differ- ential   d ‚Ñ∞ Œ± Œ≤   of the tangent-point energy has order   2 s , where   s   = ( Œ≤   ‚àí   1 )/ Œ± . To build an inner product of the same order, we first define the fractional differential operator   B œÉ   , given by ‚ü®‚ü® B œÉ   u ,   v ‚ü©‚ü©   : = ‚à¨ M   2 ùíü u ( x )‚àí ùíü u ( y ) | Œ≥   ( x )‚àí Œ≥   ( y )| œÉ ùíü v ( x )‚àí ùíü v ( y ) | Œ≥   ( x )‚àí Œ≥   ( y )| œÉ dx Œ≥   d y Œ≥ | Œ≥   ( x )‚àí Œ≥   ( y )|   (12) for all sufficiently regular   u ,   v   :   M   ‚Üí   R , where   œÉ   =   s   ‚àí   1 . This operator also has order   2 s   (Appendix A.4), and plays a role analogous to the Laplacian in Section 4.1. Yet just like the Laplacian,   B œÉ   is only semidefinite , since it vanishes for functions that are constant over each component of the domain   M . Hence, it is not invertible, and cannot be used directly to solve for a descent direction‚Äîinstead we must ‚Äúregularize‚Äù   B œÉ   by adding an additional, lower-order term. 4.2.3   Low-Order Term.   A na√Øve approach to regularization, like adding some small   œµ   >   0   times the identity, yields undesirable behavior‚Äî Œµ   must be sufficiently large to have an effect, but if   Œµ is too large, motion is significantly damped. Moreover, an inner ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 6 ===
XX:6   ‚Ä¢   Yu, Schumacher, and Crane L2 gradient fractional Sobolev gradient Fig. 7. Since an   L 2   gradient flow is always perpendicular to the curve   (red) , it fails to resolve even simple cases like the one shown above, where a large near-tangential motion is needed to untangle a knot. The fractional Sobolev gradient   (blue)   permits such motions, yielding a far more efficient flow. product constructed this way will no longer exhibit predictable scaling behavior,   i.e. , rescaling the input will actually change the direction   of the gradient rather than just its magnitude‚Äîand hence can change the solution obtained by a designer. Instead, we carefully choose an additional, low-order term   B 0 œÉ   that not only provides the right scaling behavior, but also enables us to steer the flow more quickly toward self-avoiding configurations (Figure 7). In particular, we add the term   ‚ü®‚ü® B 0 œÉ   u ,   v ‚ü©‚ü© , given by ‚à¨ M   2 k 2 4   ( Œ≥   ( x ) ,   Œ≥   ( y ) , T   ( x ))  ( u ( x )‚àí u ( y ))( v ( x )‚àí v ( y )) | Œ≥   ( x )‚àí Œ≥   ( y )| 2 œÉ   + 1   dx Œ≥   d y Œ≥   ,   (13) where   k Œ± Œ≤   is the tangent-point kernel given in Equation 3. See Ap- pendix A.4 for further discussion. 4.2.4   Sobolev-Slobodeckij Gradient.   Following Equation 5, our final gradient   grad H   s Œ≥   is defined via the fractional inner product: ‚ü®‚ü® grad H   s Œ≥   ‚Ñ∞ Œ± Œ≤   ,   X   ‚ü©‚ü© H   s Œ≥   =   d ‚Ñ∞ Œ± Œ≤   | Œ≥   ( X   ) ,   for all   X   :   M   ‚Üí   R 3 .   (14) Since   grad H   s Œ≥   ‚Ñ∞ Œ± Œ≤   and   X   are vector- rather than scalar-valued, we apply the inner product componentwise. In other words, grad H   s Œ≥   ‚Ñ∞ Œ± Œ≤   =   ¬Ø A ‚àí 1 œÉ   grad L 2   ‚Ñ∞ Œ± Œ≤   | Œ≥   ,   (15) where   ¬Ø A œÉ   denotes componentwise application of   A œÉ   . Note that the combined operator   A œÉ   =   B œÉ   +   B 0 œÉ   still has   globally   constant functions in its kernel, corresponding to global translations. To make Equation 15 well-defined, we can simply add any constraint that fixes the translation of the curve (Section 5.3). In practice, we never need a closed-form expression for the gradient, nor do we explicitly invert the operator   A œÉ   ; instead, we solve Equation 8 numerically. 5   DISCRETIZATION We now use the inner product from the previous section to derive an efficient numerical scheme for minimizing the tangent-point energy. Our discretization operates on polygonal curves. While in principle splines could be used   √† la   Bartels et al   .   [2018], in practice this makes little difference due to the use of numerical quadrature in both cases. The description given here assumes a na√Øve implementation using dense matrices and an   O ( n 2 )   evaluation of the energy and its differential; hierarchical acceleration is described in Section 6. Fig. 8.   Left:   notation used for discrete curves.   Right:   Our discrete energy is obtained by applying the trapezoidal rule to the smooth energy for each edge pair   I   ,   J   . Notation.   In the discrete setting, we will model any collection of curves and loops (including several curves meeting at a common point) as a graph   G   =   ( V   ,   E )   with vertex coordinates   Œ≥   :   V   ‚Üí   R 3 (Figure 8); we use   | V   |   and   | E |   to denote the number of vertices and edges,   resp.   For each edge   I   ‚àà   E   with endpoints   i 1 ,   i 2 , we use ‚Ñì I   : =   | Œ≥ i 1   ‚àí   Œ≥ i 2   | ,   T I   : =   ( Œ≥ i 2   ‚àí   Œ≥ i 1   )/ ‚Ñì I   ,   and   x I   : =   ( Œ≥ i 1   +   Œ≥ i 2   )/ 2 to denote the edge length, unit tangent, and midpoint,   resp.   For any quantity   u   :   V   ‚Üí   R   on vertices we use   u I   : =   ( u i 1   +   u i 2   )/ 2   to denote the average value on edge   I   =   ( i 1 ,   i 2 ) , and   u [ I   ]   : =   [ u i 1   u i 2   ] T to denote the   2   √ó   1   column vector storing the values at its endpoints. Finally, we refer to any pair   ( T   ,   x ) ‚àà   R 6   as a   tangent-point . 5.1   Discrete Energy Since the tangent-point energy is infinite for polygonal curves [Strzelecki and von der Mosel 2017, Figure 2.2], we assume that   Œ≥   is in- scribed in some (unknown) smooth curve, and apply numerical quadrature to the smooth en- ergy   ‚Ñ∞ Œ± Œ≤   . The resulting discrete energy then approximates the energy of any sufficiently smooth curve passing through the vertices   Œ≥ i   . We start by integrating   k Œ± Œ≤   over all pairs of edges: √ï I   ‚àà E √ï J   ‚àà E ‚à´ ¬Ø I ‚à´ ¬Ø J k Œ± Œ≤   ( Œ≥   ( x ) ,   Œ≥   ( y ) , T I   )   dx Œ≥   d y Œ≥   .   (16) Here   ¬Ø I   denotes the interval along edge   I   . As given, this expression is ill-defined since two edges with a common endpoint contribute infinite energy. One idea is to instead use a term involving the curvature of the circle passing through the three distinct endpoints (in the spirit of Equation 1). However, such terms would contribute nothing to the energy in the limit of regular refinement (Figure 9)‚Äî hence, we simply omit neighboring edge pairs. Applying the (2D) trapezoidal rule to Equation 16 then yields a discrete energy ÀÜ ‚Ñ∞ Œ± Œ≤   ( Œ≥   )   =   √ç √ç I   ,   J   ‚àà E , I   ‚à© J   = ¬ú (   ÀÜ k Œ± Œ≤   ) I   J   ‚Ñì I   ‚Ñì J   ,   (17) where   ÀÜ k   is the discrete kernel (   ÀÜ k Œ± Œ≤   ) I   J   : =   1 4 √ç i   ‚àà I √ç j   ‚àà J   k Œ± Œ≤   ( Œ≥ i   ,   Œ≥ j   , T I   ) .   (18) The discrete differential is then simply the partial derivatives of this energy with respect to the coordinates of all the curve vertices: d   ÀÜ ‚Ñ∞ Œ± Œ≤   | Œ≥   =      ‚àÇ ‚Ñ∞ Œ± Œ≤   / ‚àÇ Œ≥ 1   ¬∑ ¬∑ ¬∑   ‚àÇ ‚Ñ∞ Œ± Œ≤   / ‚àÇ Œ≥   | V   |    ‚àà   R 3 | V   |   . These derivatives can be evaluated via any standard technique ( e.g. , by hand, or using symbolic or automatic differentiation). ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 7 ===
Repulsive Curves   ‚Ä¢   XX:7 Fig. 9. The tangent-point energy is a double integral of the kernel   k   Œ± Œ≤   (right) over the curve   Œ≥   (left) . Since this kernel is only weakly singular, omitting diagonal terms has an insignificant effect on the overall energy. 5.2   Discrete Inner Product As in the smooth setting, we define our inner product matrix as a sum   A   =   B   +   B 0   of high-order and low-order terms   B ,   B 0   ‚àà R | V   |√ó| V   |   (as defined below). For   R 3 -valued functions, we also define a corresponding   3 | V   | √ó   3 | V   |   matrix A   = Ô£Æ Ô£Ø Ô£Ø Ô£Ø Ô£Ø Ô£∞ A A A Ô£π Ô£∫ Ô£∫ Ô£∫ Ô£∫ Ô£ª .   (19) Mirroring Equation 8, the discrete (fractional) Sobolev gradient g   ‚àà   R 3 | V   |   is then defined as the solution to the matrix equation Ag   =   d   ÀÜ ‚Ñ∞ Œ± Œ≤   .   (20) 5.2.1   Discrete Derivative Operator.   For each edge   I   ‚àà   E   we approx- imate the derivative   ùíü u   of a function   u   :   M   ‚Üí   R   (Equation 11) via the finite difference formula   1 ‚Ñì I   ( u i 2   ‚àí   u i 1   ) T I   , where   u i   denotes the value of   u   sampled at vertex   i . The corresponding derivative matrix D   ‚àà   R 3 | E   |√ó| V   |   can be assembled from local   3   √ó   2   matrices D I   =   1 ‚Ñì I   [ ‚àí T I   T I   ] . 5.2.2   Discrete High-Order Term.   We approximate the high-order part of the inner product   ‚ü®‚ü® B œÉ   u ,   v ‚ü©‚ü©   as u T Bv   = √ï √ï I   ,   J   ‚àà E , I   ‚à© J   = ¬ú w I   J   ‚ü® D I   u [ I   ] ‚àí   D J   u [ J   ] ,   D I   v [ I   ] ‚àí   D J   v [ J   ]‚ü© ,   (21) where the weights   w I   J   arise from applying trapezoidal quadrature to the denominator in Equation 25: w I   J   : =   1 4   ‚Ñì I   ‚Ñì J √ç i   ‚àà I √ç j   ‚àà J   1 | Œ≥ i   ‚àí Œ≥ j   | 2 œÉ   + 1   . The entries of the corresponding Gram matrix   B   ‚àà   R | V   |√ó| V   |   are obtained by differentiating Equation 21 with respect to the entries of   u   and   v . More explicitly, starting with the zero matrix one can build   B   by making the following increments for all pairs of disjoint edges   I   ‚à©   J   =   ¬ú , and all pairs of values   a ,   b   ‚àà { 1 ,   2 } : B i a   i b   +=   ( ‚Äì 1 ) a + b w I   J   / ‚Ñì 2 I   ,   B i a   j b   ‚àí =   ( ‚Äì 1 ) a + b w I   J   ‚ü® T I   , T J   ‚ü©/( ‚Ñì I   ‚Ñì J   ) , B j a   j b   +=   ( ‚Äì 1 ) a + b w I   J   / ‚Ñì 2 J   ,   B j a   i b   ‚àí =   ( ‚Äì 1 ) a + b w I   J   ‚ü® T J   , T I   ‚ü©/( ‚Ñì J   ‚Ñì I   ) . Fig. 10. To enforce constraints   Œ¶ ( Œ≥   )   =   0   on the curve, we both project the gradient   –¥   onto the tangent of the constraint set, and also apply an iterative procedure to project the curve itself back onto the constraint set. In both cases, the fractional Sobolev norm provides the definition of closeness. 5.2.3   Discrete Low-Order Term.   To discretize the low-order term B 0 œÉ   (Section 4.2.3), we use a different discrete weight w 0 I   J   : =   1 4   ‚Ñì I   ‚Ñì J √ï i   ‚àà I √ï j   ‚àà J k 2 4   ( Œ≥ i   ,   Œ≥ j   , T I   ) | Œ≥ i   ‚àí   Œ≥ j   | 2 œÉ   + 1   , and define a matrix   B 0   ‚àà   R | V   |√ó| V   |   , given by the relationship u T B 0 v   = √ï √ï I   ,   J   ‚àà E , I   ‚à© J   = ¬ú w 0 I   J   ( u I   ‚àí   u J   )( v I   ‚àí   v J   ) . Following a similar derivation as above, this matrix can be con- structed via the following increments: B 0 i a   i b   + =   1 4   w 0 I   J   ,   B 0 i a   j b   ‚àí   =   1 4   w 0 I   J   , B 0 j a   i b   ‚àí   =   1 4   w 0 I   J   ,   B 0 j a   j b   + =   1 4   w 0 I   J   . 5.3   Constraints For design applications, we will need to impose a variety of scalar constraints   Œ¶ i   ( Œ≥   )   =   0 ,   i   =   1 , . . . ,   k , which we encode as a single constraint function   Œ¶   :   R 3 | V   |   ‚Üí   R k   (Section 8.1). To enforce these constraints, we project the gradient onto a valid descent direction (Section 5.3.1); after taking a step in this direction, we also project the result onto the constraint set (Section 5.3.2). 5.3.1   Gradient Projection.   Let   C   : =   d Œ¶ ( Œ≥   )   be the Jacobian matrix of the constraint, and let   g   : =   grad H   s Œ≥   E   ‚àà   R 3 | V   |   denote the uncon- strained energy gradient. We seek the descent direction   Àú g   that is closest to   g   with respect to the fractional Sobolev norm, but which is also tangent to the constraint set: min Àú g 1 2   ||   Àú g   ‚àí   g || 2 H   s Œ≥   s.t.   C   Àú g   =   0 . Writing   || v   || 2 H   s Œ≥   as   v T A v   (Section 5.2), we can apply the method of Lagrange multipliers to obtain the usual first-order optimality conditions, given by the saddle point system    A   C T C   0     Àú g Œª  =    d ‚Ñ∞ Œ± Œ≤   | T Œ≥ 0  ,   (22) where   Œª   ‚àà   R k   are the Lagrange multipliers, and we have applied the identity   Ag   =   d ‚Ñ∞ Œ± Œ≤   | T Œ≥   (Equation 20). ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 8 ===
XX:8   ‚Ä¢   Yu, Schumacher, and Crane Fig. 11. To accelerate evaluation of the tangent-point energy, we build a bounding volume hierarchy that partitions both positions   (left)   and tangent directions   (right) , here drawn as a curve on the unit sphere. 5.3.2   Constraint Projection.   Suppose that we take a small step of size   œÑ   along the projected gradient direction   Àú g   to get a new candidate curve   Àú Œ≥   : =   Œ≥   ‚àí   œÑ   Àú g . To project this curve back onto the constraint set, we will apply an approximation of Newton‚Äôs method that is faster to evaluate. In particular, to find a displacement   x   ‚àà   R 3 | V   | that takes us from   Àú Œ≥   back toward the constraint set   Œ¶ ( g )   =   0 , we solve the problem min x 1 2   x T Ax   s.t.   Cx   =   ‚àí Œ¶ (   Àú Œ≥   ) . We then update our guess via   Àú Œ≥   ‚Üê   Àú Œ≥   +   x   and repeat until the con- straint violation   Œ¶ (   Àú Œ≥   )   is numerically small ( 10 ‚àí 4   in our experiments). In practice, this process rarely takes more than three iterations. At each iteration,   x   is obtained by solving the saddle point problem    A   C T C   0     x Œº  =    0 ‚àí Œ¶ (   Àú Œ≥   )  ,   (23) where   Œº   ‚àà   R k   are Lagrange multipliers. 5.4   Time Stepping A judicious choice of time step can significantly improve the effi- ciency of the flow. One strategy is to use the first time step   œÑ max   at which a collision occurs as the starting point for a line search, which guarantees that the curve remains in the same isotopy class. (Similar approaches have been used in,   e.g. ,   KnotPlot   [Scharein 1998] for knot untangling, and by Smith and Schaefer [2015] for surface parameter- ization.) Computing this time step via standard techniques [Redon et al   .   2002] costs about as much as a single energy evaluation,   i.e. , significantly less than the overall cost of a single time step. From here we apply standard backtracking line search [Boyd and Vanden- berghe 2004, Algorithm 9.2]; as a heuristic, we start this search at 2 3   œÑ max . We use this strategy throughout Section 7. An even simpler strategy that works well in practice (but comes with no collision guarantees) is to just normalize the gradient and perform backtracking line search starting with   œÑ   =   1 , until both (i) the Armijo condition is satisfied and (ii) constraint projection succeeds (Section 5.3.2). We use this latter strategy for all application examples in Section 8. We stop when the   L 2   norm of the fractional Sobolev gradient goes below a user-specified tolerance   Œµ . In our examples we use   Œµ   =   10 ‚àí 4 , though of course for design applications one can also stop whenever the results are aesthetically pleasing. 6   ACCELERATION Computational design problems can entail large collections of curves with many thousands of vertices (Section 8). Optimization hence becomes expensive since it involves not only an all-pairs energy (Section 5.1), but also inverting a dense inner product (Section 5.2). However, since the kernel falls off rapidly in space, we can use hierarchical approximation to avoid a   Œ© (| V   | 2 )   time and storage cost. Though our high-level approach is reasonably standard, careful consideration of the tangent-point energy is needed to develop a scheme that is efficient, easy to implement, and handles general nonlinear constraints. To streamline exposition, we reserve the details of this scheme for Appendix B; at a high level it consists of three main parts, outlined below. Note that since we care only about finding a good descent direction‚Äîand not accurately simulating a dynamical trajectory‚Äîwe are free to use low-order schemes, which still provide good preconditioning. Empirically, the overall strategy exhibits near-linear scaling in both time and memory (Figure 20). 6.1   Energy and Differential Evaluation To accelerate evaluation of the energy   ÀÜ ‚Ñ∞ Œ± Œ≤   and its differential, we apply the   Barnes-Hut algorithm   from   N   -body simulation [Barnes and Hut 1986]. The basic idea is to approximate distant energy contributions by aggregating values in a spatial hierarchy. In our case, this hierarchy must have six dimensions rather than three, since   ÀÜ ‚Ñ∞ Œ± Œ≤   depends on both positions   Œ≥   ‚àà   R 3   and tangents   T   ‚àà   R 3 . In lieu of a standard octree we therefore use an axis-aligned   bounding volume hierarchy (BVH) , for which additional dimensions do not incur significant cost (Figure 11). Appendix B.1 gives further details. 6.2   Hierarchical Matrix-Vector Product For optimization we need to solve linear systems involving so-called kernel matrices . Any such matrix   K   ‚àà   R | E   |√ó| E   |   has a special form K I   J   =   k ( p I   ,   p J   ) ‚Ñì I   ‚Ñì J   , where the kernel   k   maps a pair of tangent-points to a real value (Section 3). If   k   is a sufficiently regular, then   K   is well-approximated by a   hierarchical matrix   [Hackbusch 2015],   i.e. , a matrix of low- rank blocks (Figure 12). Encoding this matrix as a   block cluster tree (BCT)   enables fast matrix-vector multiplication via the   fast multipole method   [Greengard and Rokhlin 1997]. Like the BVH, our BCT involves both positions   and   tangents; in fact, each BCT block corresponds to a pair of BVH nodes. See Appendix B.2 for details. inadmissible admissible Fig. 12.   Left:   A kernel matrix K encodes interactions between all pairs of edges.   Center:   To accelerate multiplication, this matrix is approximated by rank-1 blocks   b K ùíú‚Ñ¨   , corresponding to pairs   ( ùíú ,   ‚Ñ¨ )   of distant BVH nodes. Right:   For pairs that are too close, this approximation is   inadmissible , and we must use the original matrix entries. ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 9 ===
Repulsive Curves   ‚Ä¢   XX:9 Fig. 13. We accelerate linear solves using multigrid on a hierarchy of curves. 6.3   Multigrid Solver Since the hierarchical matrix-vector multiply does not build an ex- plicit matrix, we use an iterative method to solve our linear systems. Empirically, off-the-shelf methods such as   GMRES   and   BiCGStab are not well-suited for our problem. Instead, we use geometric multi- grid (Figure 13), since (i) it is straightforward to coarsen a curve network, and (ii) the low frequency modes of our Laplace-like op- erators are well-captured on a coarse mesh. In the Euclidean case, this type of approach has been used successfully by Ainsworth and Glusa [2017]. Appendix B.3 describes our geometric coarsen- ing/prolongation operators, as well as our multigrid strategy for both Sobolev gradient evaluation and constraint projection. 7   EVALUATION AND COMPARISONS We performed extensive evaluation and comparisons of our frac- tional Sobolev descent strategy relative to other methods. Here we give an overview of results; a detailed account of how these eval- uations were performed can be found in supplemental material. Detailed comparisons were implemented in   Mathematica , using sparse numerical linear algebra from   SuiteSparse ; identical code was used for derivative computations across all methods. 7.1   Dataset We created two datasets of difficult knot embeddings:   Knot128 , which contains random embeddings of 128 distinct isotopy classes from   KnotPlot ‚Äôs ‚Äúknot zoo,‚Äù and   Trefoil100 , which contains 100 random embeddings of the trefoil knot (Figure 14). We also used the Freedman unknot   (Figure 2,   top left ), which is a standard ‚Äúchallenge problem‚Äù from the knot energy literature [Scharein 1998, Section 3.3]. To examine scaling under refinement, we performed regular refinement on knots from each of these sets. K128   T100 Fig. 14. To evaluate performance, we built a ‚Äústress test‚Äù dataset of 128 random embeddings of different knot classes   (left)   and 100 random embed- dings of the trefoil knot   (right) . The tangent point energy drives these curves toward much simpler embeddings, as shown here. 7.2   Performance Comparisons We compared our fractional Sobolev descent strategy to a variety of methods from op- timization and geometry processing. Over- all, methods that use our fractional precon- ditioner performed best, especially as prob- lem size increases. We first ran all methods on several resolutions of a small set of test curves (Figure 18); we then took the fastest methods, and ran them on all 228 curves from our two datasets (Figure 19). For simplicity we did not use hierarchical acceleration in our method (and instead just solve dense sys- tems), which gave a   significant   performance advantage to alternative methods (which are based on sparse solves). Even with this handicap, the fractional approach outperformed all other methods; as indicated in Figure 20, hierarchical acceleration would widen this gap even further. Impor- tantly, previous methods also have a much higher failure rate at untangling difficult curves such as those in our dataset (Figure 19). Further, cases on which the fractional approach itself fails generally contain near-intersections in the initial configuration (inset), which also lead to failures in most or all other methods. Note that some previous methods do not directly handle hard nonlinear constraints; for these methods we perform an apples-to- apples comparison by replacing‚Äîin   all   methods‚Äîhard edge length constraints with a soft elastic penalty (see supplemental material for further details). Knot untangling methods.   We first compared to two well-known methods for knot untangling (Figure 15):   KnotPlot , based on the so- called   symmetric energy , and   shrink on no overlaps (SONO)   [Piera≈Ñski 1998] which performs a local iterative projection in the spirit of contemporary   position-based dynamics   [M√ºller et al   .   2007]. Both methods successfully untangle the Freedman knot, but only after tens of thousands of iterations [Scharein 1998, Figure 7.6]. The basic reason is that, like   L 2   descent, such methods focus on reduction of local error, making global convergence quite slow. 1st-order methods.   Figure 16 indicates that basic 1st-order schemes like ordinary   L 2   gradient descent, L-BFGS using 10, 30, or 100 vec- tors, and nonlinear conjugate gradients   √† la   Fletcher and Reeves [1964] exhibit poor performance relative to our fractional scheme KnotPlot 2500 iterations   fractional Sobolev 120 iterations SONO 2500 iterations Fig. 15. Our fractional Sobolev strategy is dramatically more efficient than previous methods for knot untangling‚Äîhere we untangle the unknot from Figure 2. Neither KnotPlot nor SONO converged after several hours. ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 10 ===
XX:10   ‚Ä¢   Yu, Schumacher, and Crane 0   100   200   300   400   500   600 energy vs. wall clock time (s) energy vs. iteration 0   5   10   15   20 0 5 10 15 20 25 30 35 L   2   (explicit) L   2   (implicit,frozen) L   2   (implicit,Newton) L   2   (stochastic)   H   s   (stochastic) H   s   (explicit) H   s   (implicit,frozen) H   s   (implicit,Newton) H   2   (explicit) H   2   (implicit,frozen) H   2   (implicit,Newton) H   1   (explicit) H   1   (implicit,frozen) H   1   (implicit,Newton) L- BFGS (100) L- BFGS (30) L- BFGS (10) CG CG (stochastic) H   1 (implicit, Newton) H   1 (implicit, frozen) H   1 (explicit) H   2 (implicit, Newton) H   2 (implicit, frozen) H   2 (explicit) H   s (implicit, Newton) H   s (implicit, frozen) H   s (explicit) Hs (stochastic) L   2 (implicit, Newton) L   2 (implicit, frozen) L   2 (explicit) L-BFGS (10) L-BFGS (30) L-BFGS (100) CG   CG (stochastic) L   2 (stochastic) Fig. 16. Across a wide variety of descent methods and inner products, our fractional Sobolev approach does significantly better both in terms of energy reduction per iteration   (middle left)   and real-world run time   (middle right) . At top we show results for an equal amount of compute time. in terms of both wall clock time and number of iterations. This example also indicates that for   1   <   s   <   2 , the next smallest or largest   integer   Sobolev preconditioners ( H   1   and   H   2 ) underperform the fractional   H s   preconditioner, whether using explicit (forward) or implicit (backward) Euler. We solve the backward Euler update equation using Newton‚Äôs method, either by updating the Hessian for each Newton step (‚ÄúNewton‚Äù), or ‚Äúfreezing‚Äù the Hessian at the beginning of the time step (‚Äúfrozen‚Äù). If Newton‚Äôs method fails to converge within a few (10) iterations, the step size is halved and the solve is reattempted. We also tried stochastic gradient descent (SGD) with respect to the   L 2   inner product, implemented by subsampling a fixed proportion (25% in our trials) of edge pairs   ( u ,   v )   for each edge u   in each iteration for energy and gradient evaluation. This method did far worse than any other scheme we tried. SGD with respect to H s   works better, but the speedup from stochastic evaluation does not compensate for the poor quality of the descent direction. 2nd-order methods.   Second-order schemes like Newton‚Äôs method can be adapted to nonconvex problems by projecting the Hessian onto a nearby positive-semidefinite matrix. Since a global projection is prohibitively expensive, a heuristic sometimes used in geometric optimization is to project and sum up the Hessians of each local energy term [Teran et al. 2005]; in our case we can decompose the energy into the edge-edge terms from Equation 17. Though this heuristic can work well for,   e.g. , elastic energies, it does not appear to work very well for the tangent-point energy, and for larger examples had among the slowest run times of any scheme we tried (Figure 18). convexified Newton convexified Newton L 2   projected gradient L   2   projected gradient initial curve (knot0064_1024E) initial curve (knot0064_1024E) AQP AQP H   1   projected gradient H   1   projected gradient H   s   projected gradient H   s   projected gradient   H   s   NCG H   s   NCG   H   s   L-BFGS H   s   L-BFGS H   1   NCG H   1   NCG   H   1   L-BFGS H   1   L-BFGS   H   2   projected gradient H   2   projected gradient Fig. 17. The tangent point energy appears to have relatively few local min- ima; hence, different descent strategies tend to find the same local minimiz- ers (though some, like   L 2 , do not find solutions in a reasonable amount of time). See supplemental material for several hundred more examples. Quasi-Newton methods.   Several recent methods from geometry processing apply Sobolev-like preconditioning to elastic energies, such as those used for shape deformation or surface parameter- ization [Kovalsky et al   .   2016; Claici et al   .   2017; Zhu et al .   2018]. Since the highest-order term in such problems often looks like a Dirichlet energy,   H   1   preconditioning via the Laplacian   ‚àÜ   can be an effective starting point for optimization (as discussed in Section 4.1). However, such preconditioners do not perform as well as our frac- tional preconditioner, since they are not as well-matched to the order of the differential   d ‚Ñ∞ Œ± Œ≤   . For instance, as seen in Figure 18, the AQP strategy of Kovalsky et al   .   [2016] significantly underperforms our preconditioner when the Laplacian is used as the quadratic proxy; using our fractional operator as the quadratic proxy improves performance‚Äîbut of course requires the machinery introduced in this paper. Another possibility is to use Laplacian-initialized L-BFGS (in the spirit of Zhu et al   .   [2018]); we found this strategy works a bit better than AQP, but again not as well as the fractional precon- ditioner. We also considered several variants of these strategies, such as applying Nesterov acceleration, and combining nonlinear conjugate gradients (NCG)   √† la   Polak and Ribiere [1969] or L-BFGS with our fractional preconditioner. For hard constraints we advocate the use of our fractional ( H s   ) projected gradient scheme (as detailed in Section 5); if soft constraint enforcement is acceptable, then L- BFGS or   H s   -preconditioned NCG are both good options: the former converges faster near minima; the latter gets stuck less often. 7.3   Local minimizers As seen in Figure 17, the local minimizers found via our fractional descent strategy generally appear to be the same as with other schemes, up to rigid motions. Hundreds more such examples can be found in the supplemental material. Very rarely, two different methods produced local minimizers that were identical up to a reflection ; such   amphichiral   pairs exist in some knot classes [Liang and Mislow 1994], but of course have the same energy. ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 11 ===
Repulsive Curves   ‚Ä¢   XX:11 0   160   320   480 0 1k 2k 3k 4k   energy time (s) 160 0 0 1k 2k 3k 4k   energy 320   160 0 0 1k 2k 3k 4k   energy 320   iterations iterations iterations   160 0 0 1k 2k 3k 4k   energy 320 high resolution (1648 edges) low resolution (412 edges)   medium resolution (824 edges) ours ours ours   ours 0 1k 2k 3k 4k   energy time (s) 0   100 50 ours ours 0 1k 2k 3k 4k   energy time (s) 200 100   300 0 L   2   L-BFGS [sparse] L   2   NCG [sparse] L   2   Nesterov [sparse] AQP [sparse] convexified Newton NCG [ dense ] fractional ( H   s   ) AQP [ dense ] fractional ( H   s   ) L-BFGS [ dense ] fractional ( H   s   ) NCG [ dense ] fractional ( H   s   ) Nesterov [ dense ] Laplacian ( H   1   ) L-BFGS [sparse] Laplacian ( H   1   ) NCG [sparse] Laplacian ( H   1   ) Nesterov [sparse] soft constraint methods ‚Äî stuck/time out energy 0   300   600   900 0 1k 2k 3k 4k high resolution (1648 edges) time (s) low resolution (412 edges) time (s) 200   300 100 0 0 1k 2k 3k 4k medium resolution (824 edges) time (s) 800 600 400 200 0 0 1k 2k 3k 4k   energy energy   160 0 0 1k 2k 3k 4k   energy 320 160 0 0 1k 2k 3k 4k   energy 320   iterations   iterations 160 0 0 1k 2k 3k 4k   energy 320   iterations ours ours ours   ours ours   ours   L   2   projected gradient [sparse] convexified Newton   [ dense ] fractional ( H   s ) projected gradient [ dense ] fractional ( H   s ) projected gradient ‚Äî implicit [ dense ] Laplacian ( H   1 ) projected gradient [sparse] bi-Laplacian ( H   2 ) projected gradient [sparse] L   2   projected gradient ‚Äî implicit [sparse] hard constraint methods ‚Äî stuck/time out low resolution (FreedmanHeWang_00412E) medium resolution (FreedmanHeWang_00824E) high resolution (FreedmanHeWang_01648E) Fig. 18. We compared our descent strategy to a variety of 1st-order, 2nd-order, and quasi-Newton strategies, using both hard constraints (top) and a soft penalty (bottom) to preserve length. Here we show energy versus both time and iteration count for several resolutions of the initial curve from Figure 2; tests on additional curves yield very similar results (see supplemental material). Note that we achieve the best real-world clock time‚Äîeven though we compare a dense implementation of our method (without hierarchical acceleration) to sparse versions of other schemes. ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 12 ===
XX:12   ‚Ä¢   Yu, Schumacher, and Crane 101 stuck (47.2%), 37 nonconvergent (17.3%) 138 total failed (64.5%) 130 stuck (60.7%), 67 nonconvergent (31.3%) 197 total failed (92.1%) 14 stuck (6.5%) 14 total failed (6.5%) 10   2   10   3 10   2 10   3 18 stuck (8.4%), 196 nonconvergent (91.6%) 214 total failed (100.0%) 29 stuck (13.6%), 180 nonconvergent (84.1%) 209 total failed (97.7%) 2x reference time reference time 4x reference time (214 curves total) Hard constraint methods time (s) to achieve 1.1x minimal energy (log-log plot) time (s) for fractional (Hs) projected gradient 180 stuck (85.7%) 180 total failed (85.7%) 105 stuck (50.0%), 1 nonconvergent (0.5%) 106 total failed (50.5%) 139 stuck (66.2%) 139 total failed (66.2%) 31 stuck (14.8%) 31 total failed (14.8%) 7 stuck (3.3%) 7 total failed (3.3%) 10   1   10   2 10   1 10   2 0.5x reference iterations reference iterations 2x reference iterations 4x reference iterations (210 curves total) Soft constraint methods iterations to achieve 1.1x minimal energy (log-log plot) iterations for fractional (Hs) NCG soft constraint methods Laplacian ( H 1   ) L-BFGS [sparse] AQP Laplacian ( H 1   ) NCG [sparse] fractional ( H   s ) NCG [ dense ] fractional ( H   s ) L-BFGS [ dense ] 180 stuck (85.7%) 180 total failed (85.7%) 105 stuck (50.0%), 1 nonconvergent (0.5%) 106 total failed (50.5%) 139 stuck (66.2%) 139 total failed (66.2%) 31 stuck (14.8%) 31 total failed (14.8%) 7 stuck (3.3%) 7 total failed (3.3%) 10   1   10   2   10   3 10   1 10   3 0.5x reference time 2x reference time reference time 4x reference time (210 curves total) time (s) for fractional (Hs) NCG soft constraint methods Laplacian ( H 1   ) L-BFGS [sparse] AQP Laplacian ( H 1   ) NCG [sparse] fractional ( H s ) NCG [ dense ] fractional ( H   s ) L-BFGS [ dense ] 101 stuck (47.2%), 37 nonconvergent (17.3%) 138 total failed (64.5%) 130 stuck (60.7%), 67 nonconvergent (31.3%) 197 total failed (92.1%) 14 stuck (6.5%) 14 total failed (6.5%) 18 stuck (8.4%), 196 nonconvergent (91.6%) 214 total failed (100.0%) 29 stuck (13.6%), 180 nonconvergent (84.1%) 209 total failed (97.7%) 10   1   10   2 10   1 10   2 2x reference iterations reference iterations 4x reference iterations (214 curves total) Hard constraint methods iterations to achieve 1.1x minimal energy (log-log plot) iterations for fractional (Hs) projected gradient iterations for other methods FAILED FAILED FAILED FAILED iterations for other methods time (s) for other methods   time (s) for other methods Soft constraint methods time (s) to achieve 1.1x minimal energy (log-log plot) hard constraint methods Laplacian ( H 1   ) projected gradient [sparse] bi-Laplacian ( H 2   ) projected gradient [sparse] fractional ( H   s ) projected gradient [ dense ] standard ( L   2 ) projected gradient [sparse] Newton (convexified) hard constraint methods Laplacian ( H 1   ) projected gradient [sparse] bi-Laplacian ( H 2   ) projected gradient [sparse] fractional ( H   s ) projected gradient [ dense ] standard ( L   2 ) projected gradient [sparse] Newton (convexified) Fig. 19. We used a dataset of about two hundred difficult knot embeddings to evaluate the performance of our strategy compared to the next most competitive methods. Even without hierarchical acceleration, our fractional strategy was significantly faster‚Äîand succeeded at untangling a much larger fraction of knots. Here we plot the time it took for each method to get within 1.1x of the reference energy, against the time taken by our fractional strategy. Results have been split into hard/soft constraint enforcement (top/bottom rows), and iteration count/wall clock time (left/right columns). At the top of each plot we show the number of failures after 24 minutes of compute time‚Äî stuck   indicates a failure of line search to make progress due to collisions;   nonconvergent   means the method failed to get below 1.1x of the reference energy. ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 13 ===
Repulsive Curves   ‚Ä¢   XX:13 Fig. 20. A comparison of runtime per iteration on samplings of the same curve with increasing resolution. ‚ÄúExact‚Äù indicates no acceleration, ‚ÄúBarnes- Hut‚Äù indicates accelerated gradients only, and ‚ÄúMultigrid‚Äù indicates all accelerations enabled, with and without constraint projection. Reported numbers are averages over up to 500 iterations or until convergence. 7.4   Scaling behavior We compared per-iteration costs of the unaccelerated scheme, a scheme using only Barnes-Hut (Section 6.1), and the full acceleration scheme described in Section 6‚Äîsee Figure 20. With full acceleration we observe near-linear scaling, whereas schemes that directly solve the dense system exhibit super-quadratic scaling and quickly run out of memory. Note that constraint projection with direct solvers comes nearly for free, since a factorization of Equation 23 can be reused to solve Equation 22. In contrast, no reuse is possible in the fully accelerated scheme, making constraint projection relatively expensive. Disabling this step further speeds up the accelerated scheme, but leads to constraint drift over time. Alternative methods for constraint enforcement (such as soft penalties, as noted above) might hence provide further improvement. 8   RESULTS AND APPLICATIONS Given how ubiquitous plane and space curves are in areas like geometry, graphics, robotics, and visualization‚Äîand how natural it is to want to avoid collision of such curves‚Äîour method provides a useful computational framework for a wide variety of tasks. Here we explore some preliminary applications that we hope will inspire future work. All other examples in this section completed within a few minutes, except for the 3D curve packing example where we allowed curves to grow longer for several hours as a stress test. We first describe constraints and potentials used for these examples. 8.1   Constraints and Potentials A key feature of our optimization framework is that it not only efficiently minimizes knot energies, but that it can do so in con- junction with fairly arbitrary user-defined constraints and penalties (Section 5.3). This opens the door to a rich variety of computational design applications beyond the basic ‚Äúknot untangling‚Äù that has been the focus of previous work. For the applications that will be explored in Section 8, we consider the following constraints: ‚Ä¢   Barycenter.   This fixes the barycenter of the curve to a point x 0   via the constraint   Œ¶ barycenter ( Œ≥   )   : =   √ç I   ‚àà E   ‚Ñì I   ( x I   ‚àí x 0 ) . In the absence of other constraints, this eliminates the null space of globally constant functions discussed in Appendix A. Fig. 21. Allowing curves to slide freely over constraint surfaces   (left)   enables design tasks like arranging networks of muscles or muscle fibers   (right) . ‚Ä¢   Length.   The repulsive curve energy naturally wants to make the curve longer and longer. A simple way to counteract this is via a total length constraint   Œ¶ length ( Œ≥   )   : =   L 0   ‚àí   √ç I   ‚àà E   ‚Ñì I   , where   L 0   is the target length. ‚Ä¢   Edge Length.   We can also constrain the lengths of each individual edge, allowing only isometric motions. This entails a constraint   Œ¶ length , I   ( Œ≥   )   : =   ‚Ñì 0 I   ‚àí   ‚Ñì I   for each edge   I   , where   ‚Ñì 0 I is the target edge length. ‚Ä¢   Point Constraint.   To fix the position of a vertex   i   to the point   x i   ‚àà   R 3 , we can add the constraint   Œ¶ point , i   ( Œ≥   )   : =   Œ≥ i   ‚àí x i   . ‚Ä¢   Surface Constraint.   To keep a point of the curve constrained to an implicit surface   f   ( x )   =   0 , we can add the constraint Œ¶ surface , i   ( Œ≥   )   : =   f   ( Œ≥ i   ) . ‚Ä¢   Tangent Constraint.   We can force the tangent   T I   of an edge   I   to match a unit vector   X   ‚àà   R 3   via the constraint Œ¶ tangent , I   ( Œ≥   )   : =   T I   ‚àí   X   . In several applications, we progressively increase or decrease the target length values   L 0   or   l 0 I   ; the next constraint projection step then enforces the new length. We also consider the following penalties: ‚Ä¢   Total length.   A simple energy is the total curve length, which provides a ‚Äúsoft‚Äù version of the total length constraint. Discretely, this energy is given by   ÀÜ ‚Ñ∞ length ( Œ≥   )   : =   √ç I   ‚àà E   ‚Ñì I   . ‚Ä¢   Length difference.   This energy penalizes differences in ad- jacent edge lengths, given by   ÀÜ ‚Ñ∞ diff ( Œ≥   )   =   √ç v   ‚àà V int   ( ‚Ñì I v   ‚àí   ‚Ñì J v   ) 2 , where   V int   denotes the set of ‚Äúinterior‚Äù vertices with degree 2, and   I v   and   J v   are the indicent edges to   v . ‚Ä¢   Surface potential.   Given a surface   M   ‚äÇ   R 3 , we use the energy   ‚Ñ∞ M   ( Œ≥   )   : =   ‚à´ Œ≥ ‚à´ M   1 /| x M   ‚àí   Œ≥   ( x Œ≥   )| Œ≤   ‚àí Œ±   dx M   dx Œ≥   to avoid collisions. This is effectively a Coulomb potential of the same order as   ‚Ñ∞ Œ± Œ≤   on   M . In the discrete setting,   M   is a triangulated surface, and we use a BVH on   M   to accelerate the evaluation of   ‚Ñ∞ M   and its differential, in a similar fashion to   ‚Ñ∞ Œ± Œ≤   . ‚Ä¢   Field potential.   Given a fixed unit vector field   X   on   R 3 , the energy   ‚Ñ∞ X   ( Œ≥   )   : =   ‚à´   L 0   | T   ( x ) √ó   X   ( Œ≥   ( x ))| 2   dx Œ≥   encourages   Œ≥ to run parallel (or anti-parallel) to   X   . We discretize this as ÀÜ ‚Ñ∞ X   ( Œ≥   )   : =   √ç I   ‚àà E   ‚Ñì I   | T I   √ó   X   ( x I   )| 2 . Note that the energies considered here involve lower-order deriva- tives than those in   ‚Ñ∞ Œ± Œ≤   , and do not therefore have a major effect on the stiffness of the overall system. Hence, we can continue to use the fractional Sobolev inner product without modification to define an efficient gradient flow. ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 14 ===
XX:14   ‚Ä¢   Yu, Schumacher, and Crane Fig. 22. Just as repulsive potentials are used to equally-distribute points, we can compute collections of equally-spaced curves (here constrained to a region via a fixed curve potential). Fig. 23. We can pack curves into a domain by penalizing their proximity to its boundary, and progressively increasing edge length. (Here we render curves with a non-circular cross section, which is not modeled by the energy.) 8.2   Curve Packing Packing problems (such as   bin packing ) appear throughout geometry and computer graphics, playing an important role in,   e.g. , 2D layouts for manufacturing or UV atlas generation. An adjacent problem is generation of regular sampling patterns,   e.g. , blue noise sampling via Poisson disk rejection. The ability to optimize large families of repulsive curves enables us to solve analogous ‚Äúcurve packing‚Äù problems‚Äîfor instance, in Figure 22, we use a fixed boundary curve to pack disks of increasing length; likewise, in Figures 1 and 23, we use a surface penalty to pack increasingly long curves into a target region. Figure 24 likewise packs increasingly long curves on a surface. Going the opposite direction, we can also   decrease   length while encouraging repulsion to generate clean illustrations that are difficult to draw by hand (Figure 25). Finally, by constraining only parts of curves to lie on surfaces, we can design biologically-inspired curve networks such as muscle fibers (Figure 21), which are attached to objects at their endpoints but are otherwise free. 8.3   Graph Drawing A basic problem in data visualization is drawing   graphs ; a typical approach is to use a force-based layout that seeks to avoid,   e.g. , col- lisions between nodes, or over/under-extension of edges [Fruchter- man and Reingold 1991]. Our framework makes it easy to optimize the geometry of the edges themselves, opening the door to graph layouts that are both more compact and more legible (Figure 26). We can also use this machinery to obtain legible drawings of nonplanar graphs, by perturbing a planar embedding (Figure 27); here, the ability to preserve lengths conveys information about edge weights. A particularly interesting graph embedding problem is the design Fig. 24. Patterns obtained by constraining a collection of repulsive curves to a surface and increasing their lengths (initial states shown above their final configurations). output input sketch #1 sketch #2 Fig. 25. Topologically intricate loops can be difficult to draw by hand‚Äîthe sketches at left were done by Nathan Dunfield to illustrate   Dehn-Thurston coordinates. At right we generate an equispaced version of this curve by flowing a rough sketch, subject to an implicit surface constraint. 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86   87 88   89 90 91 92 93 94 95 96 97 98 99 0 1 2   3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29   30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86   87   88   89   90   91   92   93   94 95 96 97 98 99 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41   42 43 44 45 46 47 48 49 50 51 52 53 54 55 56   57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73   74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 neato twopi ours Fig. 26. Traditional 2D graph drawing algorithms based on nodal proximity may cause edges to cross   (left)   or position nodes extremely close together (center) ; these layouts were produced by the popular   Graphviz   library [Ellson et al .   2001]. By treating edges as repulsive curves, we can obtain graph drawings that are both more compact and more legible   (right) . of synthetic hydrogel   vascular networks   [Grigoryan et al   .   2019]; Fig- ure 28 shows a simple example where we optimize a multivascular network (starting from subgraphs of a tet mesh and its dual). ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 15 ===
Repulsive Curves   ‚Ä¢   XX:15 Fig. 27. Isometric embedding: by jittering 2D drawings of non-planar graphs (which necessarily have crossings), curve repulsion with length constraints yields nicely spaced embeddings in   R 3   with prescribed edge lengths. initial   initial optimized optimized Fig. 28.   Left:   a crude initial topology for a synthetic vascular network   (left) is optimized to achieve more uniform delivery of nutrients throughout a volume.   Right:   plotting the maximum collision-free thickness helps to visualize the improvement in uniformity. L Note that at junctures between more than two edges, the tangent-point energy will al- ways be large (since three or more edges can- not be collinear), rapidly forcing vertices away from each other. This can be counteracted by constraining their edge lengths, forcing the vertices to lie on spheres of constant radii around the junctures. 8.4   Self-Avoiding Splines Beyond standard B√©zier input, sophisticated tools have been de- veloped for drawing spline curves‚Äîbut do not consider the basic constraint of ensuring that curves do not cross themselves (which is often desirable for physical or aesthetic reasons). For instance, Fig- ure 30 ( center ) shows the interpolation of a set of control points by Fig. 29. As with B√©zier curves, we can also control curve tangents at both interior and endpoints. Here we flow a polygonal curve   (left) , to a smooth interpolant with fixed points   (red) , and fixed points and tangents   (blue) . k-curves   ours Fig. 30. Standard curve interpolation methods in 2D drawing programs can cause curves to self-intersect   (center) , even when the control polygon   (left) does not. By starting from the control polygon and constraining the control points, we obtain a smooth, non-intersecting interpolant   (right) . k-curves   [Yan et al   .   2017], which underpin one of the basic drawing tools in Adobe Illustrator (the   Curvature Tool ). By simply apply- ing point constraints at the control points, and letting the length increase under our repulsive flow, we obtain a nice interpolating curve without self-intersection (Figure 30,   right ). In this context we can also use our tangent constraint to control the behavior of such a curve at open endpoints (Figure 29). 8.5   Multi-agent Path Planning In robotics, numerous algorithms have been developed for the prob- lem of multi-agent path planning [de Wilde et al   .   2013], wherein multiple agents must travel from fixed start to end locations with- out colliding with the environment or each other. Many algorithms operate on a discrete grid or graph [Yu and LaValle 2013], which quantizes the solution space and does not penalize near-collisions; such trajectories may therefore not be robust to sensing or control error. By treating path planning as a space-time optimization of continuous curves with fixed endpoints, we can use curve repulsion to find (or refine) trajectories that maximize collision avoidance, time initial configuration target configuration Fig. 31.   Top-left:   In this path planning scenario, an initial trajectory brings the four agents dangerously close together.   Bottom-left:   By treating trajecto- ries as curves in space-time, our system provides solutions that maximally avoid collisions, making them more robust to control errors.   Right:   Finding 2D trajectories is equivalent to optimizing a 3D braid with fixed endpoints constrained to an extrusion of the given environment. This same construc- tion can easily be generalized to 3D environments. ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 16 ===
XX:16   ‚Ä¢   Yu, Schumacher, and Crane input input   output output Fig. 32. Encouraging curve tangents to align with a given vector field im- prove the quality of streamline visualization. Here, a random set of curve segments   (top)   aligns itself with a rotational vector field; we can also opti- mize randomly sampled streamlines   (bottom)   to improve their spacing. making them more resilient to error (Figure 31). Finding such tra- jectories in   n   dimensions is equivalent to optimizing a braid in n   +   1   dimensions; since neither the size of the curve nor the cost of a BVH/BCT depends strongly on dimension, this strategy easily generalizes to three (or more) dimensions. 8.6   Streamline Visualization A common way to visualize vector fields is by tracing integral curves or   streamlines ; significant effort has gone into algorithms that pro- vide uniform spacing ( e.g. , by incrementally constructing a Delaunay triangulation [Mebarki et al   .   2005]), though such methods can be difficult to generalize to 3D volumes or vector fields on surfaces. We can generate nicely-spaced streamlines by adding a field alignment potential to the tangent-point energy‚Äîfor instance, in Figure 32 we start with a set of random curve segments, which automatically coalesce into streamlines. 9   LIMITATIONS AND CONCLUSION Since we approximate the tangent- point energy via numerical quadra- ture, it is possible for a very coarse curve to pass through the energy bar- rier. However, crossings can be pre- vented via continuous time collision detection (Section 5.4); to maintain accuracy one could also try adding more quadrature points at the previous time step if any collisions occur. For the design tasks in this paper, we did not find such strate- gies necessary. Also on very coarse meshes, edges that are extremely close together can temporarily get stuck in a near-crossing configu- ration (see inset). In this situation, the term   k 2 4   from the low-order term (Equation 13) is very large, causing the inverse of   A ‚Äîand hence the Sobolev gradient‚Äîto be very small. One idea is to use adaptive quadrature for edge pairs that are close in space, which would better resolve the near-infinite high-order term and hence push the curve apart. Given the scalability of our approach, another pragmatic solution is simply to increase the overall resolution. Fig. 33. Untangling a pair of earbuds via repulsion (see supplemental video). There are many ways to further accelerate our solver. For instance, we did not vectorize our code, parallelized only the matrix-vector multiply in non-well-separated leaves of the BCT, and did not make use of the GPU. For small time steps one might re-fit rather than re-build the BVH; likewise, it may be beneficial to incrementally update the BCT. Better line search or descent direction heuristics may also reduce the overall number of steps. Finally, a natural question is how to extend these techniques to surface   repulsion. The tangent-point energy seems attractive here since (unlike M√∂bius energy) it needs only Euclidean rather than geodesic distances. One now has double integrals over   surfaces , but might still achieve efficiency via hierarchical acceleration. In general, we are hopeful our investigation will provide valuable insight into using repulsive energies for computational design. ACKNOWLEDGMENTS Thanks to Stelian Coros for early discussion of these ideas. The bunny mesh is used courtesy of the Stanford Computer Graphics Laboratory. This work was supported by a Packard Fellowship, NSF awards 1717320 and 1943123, and gifts from Autodesk, Adobe, Activision Blizzard, Disney, and Facebook. The second author was supported by a postdoctoral fellowship of the German Academic Exchange Service (DAAD) and by the German Research Foundation (DFG) under project 282535003:   Geometric curvature functionals: energy landscape and discrete methods . The third author was also supported by NSF award DMS-1439786 and Sloan award G-2019- 11406 while in residence at ICERM. REFERENCES M. Ainsworth and C. Glusa. 2017. Aspects of an Adaptive Finite Element Method for the Fractional Laplacian.   Comput. Methods Appl. Mech. Eng.   327 (2017). B. Andrews, B. Chow, C. Guenther, and M. Langford. 2020.   Extrinsic Geometric Flows . Graduate Studies in Mathematics, Vol. 206. A. Angelidis and F. Neyret. 2005.   Simulation of smoke based on vortex filament primitives. In   Symp. Comp. Anim.   87‚Äì96. T. Ashton and J. Cantarella. 2005. A fast octree-based algorithm for computing rope- length. In   Physical And Numerical Models In Knot Theory . 323‚Äì341. T. Ashton, J. Cantarella, M. Piatek, and E. Rawdon. 2011. Knot tightening by constrained gradient descent.   Experimental Mathematics   20, 1 (2011), 57‚Äì90. Trygve B√¶rland. 2019. An Auxiliary Space Preconditioner for Fractional Laplacian of Negative Order.   arXiv preprint arXiv:1908.04498   (2019). Trygve B√¶rland, Miroslav Kuchta, and Kent-Andre Mardal. 2019. Multigrid methods for discrete fractional Sobolev spaces.   SIAM J. Sci. Comput.   41, 2 (2019), A948‚ÄìA972. https://doi.org/10.1137/18M1191488 J. Barnes and P. Hut. 1986.   A hierarchical O(N log N) force-calculation algorithm. Nature   324, 6096 (1986), 446‚Äì449. S. Bartels, P. Reiter, and J. Riege. 2018. A simple scheme for the approximation of self-avoiding inextensible curves.   IMA J. Num. Anal.   38, 2 (2018), 543‚Äì565. M. Bergou, M. Wardetzky, S. Robinson, B. Audoly, and E. Grinspun. 2008. Discrete elastic rods. In   ACM Trans. Graph. , Vol. 27. ACM, 63. S. Blatt. 2012. Boundedness and Regularizing Effects of O‚Äôhara‚Äôs Knot Energies.   Journal of Knot Theory and Its Ramifications   21, 01 (2012). S. Blatt. 2013. The Energy Spaces of the Tangent Point Energies.   Journal of Topology and Analysis   5, 3 (2013), 261‚Äì270. S. Blatt and P. Reiter. 2015. Regularity Theory for Tangent-point Energies: the Non- degenerate Sub-critical Case.   Adv. Calc. Var.   8, 2 (2015), 93‚Äì116. S. Boyd and L. Vandenberghe. 2004.   Convex Optimization . Cambridge University Press. ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 17 ===
Repulsive Curves   ‚Ä¢   XX:17 D. Braess and R. Sarazin. 1997. An Efficient Smoother for the Stokes Problem.   Applied Numerical Mathematics   23, 1 (1997), 3‚Äì19. K. Brakke. 1992. The surface evolver.   Experimental mathematics   1, 2 (1992). K. Brakke. 1994. Surface evolver manual. J. Brown, J. Latombe, and K. Montgomery. 2004. Real-time Knot-tying Simulation.   The Visual Computer   20, 2 (01 May 2004), 165‚Äì179. G. Buck and J. Orloff. 1995. A simple energy function for knots.   Top. Appl.   61, 3 (1995). J. Calvo, K. Millett, and E. Rawdon. 2002.   Physical Knots: Knotting, Linking, and Folding Geometric Objects in   R 3 . Vol. 304. American Mathematical Society. A. Chern, F. Kn√∂ppel, U. Pinkall, P. Schr√∂der, and S. Wei√ümann. 2016. Schr√∂dinger‚Äôs smoke.   ACM Trans. Graph.   35, 4 (2016), 77. S. Claici, M. Bessmeltsev, S. Schaefer, and J. Solomon. 2017. Isometry-aware precondi- tioning for mesh parameterization. In   Comp. Graph. Forum , Vol. 36. K. Crane, U. Pinkall, and P. Schr√∂der. 2013. Robust Fairing via Conformal Curvature Flow.   ACM Trans. Graph.   32, 4 (2013). B. de Wilde, A. ter Mors, and C. Witteveen. 2013. Push and rotate: cooperative multi- agent path planning. In   Proc. Conf. Auton. Agents and Multi-agent Sys. C. DeForest and C. Kankelborg. 2007. Fluxon Modeling of Low-beta Plasmas.   J. Atm. Sol.-Terr. Phys.   69, 1-2 (2007), 116‚Äì128. M. Desbrun, M. Meyer, P. Schr√∂der, and A. Barr. 1999. Implicit Fairing of Irregular Meshes Using Diffusion and Curvature Flow. In   Proc. ACM SIGGRAPH . 8. E. Di Nezza, G. Palatucci, and E. Valdinoci. 2012. Hitchhiker‚Äôs guide to the fractional Sobolev spaces.   Bull. Sci. Math.   136, 5 (2012), 521‚Äì573. I. Eckstein, J. Pons, Y. Tong, C. Kuo, and M. Desbrun. 2007. Generalized Surface Flows for Mesh Processing. In   Geometry Processing , Alexander Belyaev and Michael Garland (Eds.). The Eurographics Association. J. Ellson, E. Gansner, L. Koutsofios, S. North, and G. Woodhull. 2001. Graphviz: Open Source Graph Drawing Tools. In   Int. Symp. on Graph Drawing . 483‚Äì484. R. Fletcher and C. Reeves. 1964. Function minimization by conjugate gradients.   The computer journal   7, 2 (1964), 149‚Äì154. M. Freedman, Z. He, and Z. Wang. 1994. Mobius Energy of Knots and Unknots.   Annals of Mathematics   139, 1 (1994), 1‚Äì50. T. Fruchterman and E. Reingold. 1991. Graph drawing by force-directed placement. Software: Practice and experience   21, 11 (1991), 1129‚Äì1164. L. Greengard and V. Rokhlin. 1997. A new version of the fast multipole method for the Laplace equation in three dimensions.   Acta numerica   6 (1997). B. Grigoryan, S. Paulsen, et al .   2019. Multivascular networks and functional intravascu- lar topologies within biocompatible hydrogels.   Science   364, 6439 (2019), 458‚Äì464. W. Hackbusch. 2015.   Hierarchical matrices: algorithms and analysis . Vol. 49. Springer. D. Harmon, E. Vouga, B. Smith, R. Tamstorf, and E. Grinspun. 2009. Asynchronous Contact Mechanics. In   ACM Trans. Graph. , Vol. 28. ACM, 87. Y. Hassan, S. Easa, and A. Abd El Halim. 1998. State-of-the-art of Three-dimensional Highway Geometric Design.   Can. J. Civ. Eng.   25, 3 (1998), 500‚Äì511. D. Kleckner, L. Kauffman, and W. Irvine. 2016. How Superfluid Vortex Knots Untie. Nature Physics   12, 7 (2016), 650. S. Kovalsky, M. Galun, and Y. Lipman. 2016. Accelerated quadratic proxy for geometric optimization.   ACM Trans. Graph.   35, 4 (2016), 1‚Äì11. B. Kubiak, N. Pietroni, F. Ganovelli, and M. Fratarcangeli. 2007. A Robust Method for Real-time Thread Simulation. In   Proc. ACM Symp. Virt. Real. Soft. Tech.   ACM, 85‚Äì88. R. Kusner and J. Sullivan. 1998. M√∂bius-invariant knot energies.   Ideal knots   19 (1998). M. Kwa≈õnicki. 2017. Ten equivalent definitions of the fractional Laplace operator.   Fract. Calc. Appl. Anal.   20, 1 (2017), 7‚Äì51. M. Lackenby. 2014. Elementary Knot Theory.   Clay Mathematics Institute   (2014). A. Ladd and L. Kavraki. 2004.   Motion Planning for Knot Untangling . 7‚Äì23. C. Liang and K. Mislow. 1994. On amphicheiral knots.   J. Math. Chem.   15, 1 (1994). T. Martin, P. Joshi, M. Bergou, and N. Carr. 2013. Efficient Non-linear Optimization via Multi-scale Gradient Filtering. In   Comp. Grap. Forum , Vol. 32. 89‚Äì100. F. Maucher and P. Sutcliffe. 2016. Untangling knots via reaction-diffusion dynamics of vortex strings.   Physical review letters   116, 17 (2016), 178101. J. McCrae and K. Singh. 2009. Sketching Piecewise Clothoid Curves.   Computers & Graphics   33, 4 (2009), 452‚Äì461. A. Mebarki, P. Alliez, and O. Devillers. 2005.   Farthest point seeding for efficient placement of streamlines. In   IEEE Visualization . 479‚Äì486. H. Moreton. 1992.   Minimum curvature variation curves, networks, and surfaces for fair free-form shape design . Ph.D. Dissertation. University of California, Berkeley. M. M√ºller, B. Heidelberger, M. Hennix, and J. Ratcliff. 2007. Position based dynamics.   J. Vis. Comm. and Im. Repr.   18, 2 (2007), 109‚Äì118. J. O‚ÄôHara. 1991. Energy of a knot.   Topology   30, 2 (1991), 241‚Äì247. M. Padilla, A. Chern, F. Kn√∂ppel, U. Pinkall, and P. Schr√∂der. 2019. On bubble rings and ink chandeliers.   ACM Trans. Graph.   38, 4 (2019), 129. J. P√©rez, M. Otaduy, and B. Thomaszewski. 2017. Computational design and automated fabrication of kirchhoff-plateau surfaces.   ACM Trans. Graph.   36, 4 (2017), 62. J. P√©rez, B. Thomaszewski, et al .   2015. Design and Fabrication of Flexible Rod Meshes. ACM Trans. Graph.   34, 4 (2015). P. Piera≈Ñski. 1998. In Search of Ideal Knots. In   Ideal Knots , A. Stasiak, V. Katritch, and L. Kauffman (Eds.). Vol. 19. World Scientific. U. Pinkall and K. Polthier. 1993. Computing discrete minimal surfaces and their conju- gates.   Experimental mathematics   2, 1 (1993), 15‚Äì36. E. Polak and G. Ribiere. 1969.   Note sur la convergence de m√©thodes de directions conjugu√©es.   ESAIM: Math. Model. Num. Anal.   3, R1 (1969), 35‚Äì43. S. Redon, A. Kheddar, and S. Coquillart. 2002.   Fast continuous collision detection between rigid bodies. In   Comp. Graph. Forum , Vol. 21. 279‚Äì287. R. Renka and J. Neuberger. 1995.   Minimal Surfaces and Sobolev Gradients.   SIAM Journal on Scientific Computing   16, 6 (1995), 1412‚Äì1427. R. Scharein. 1998.   Interactive Topological Drawing . Ph.D. Dissertation. University of British Columbia. H. Schumacher. 2017. On   H   2 -gradient Flows for the Willmore Energy.   arXiv e-prints (Mar 2017). J. Smith and S. Schaefer. 2015. Bijective parameterization with free boundaries.   ACM Trans. Graph.   34, 4 (2015), 1‚Äì9. P. Strzelecki and H. von der Mosel. 2017. Geometric curvature energies: facts, trends, and open problems. In   New Directions in Geometric and Applied Knot Theory . J. Teran, E. Sifakis, G. Irving, and R. Fedkiw. 2005. Robust quasistatic finite elements and flesh simulation. In   Symp. Comp. Anim.   181‚Äì190. H. Triebel. 1983.   Theory of function spaces . Monographs in Mathematics, Vol. 78. S. Walker. 2016. Shape optimization of self-avoiding curves.   J. Comp. Phys.   311 (2016). S. Wei√ümann and U. Pinkall. 2010. Filament-based smoke with vortex shedding and variational reconnection. In   ACM Trans. Graph. , Vol. 29. Z. Yan, S. Schiller, G. Wilensky, N. Carr, and S. Schaefer. 2017. k-curves: interpolation at local maximum curvature.   ACM Trans. Graph.   36, 4 (2017). C. Yu, K. Crane, and S. Coros. 2017. Computational Design of Telescoping Structures. ACM Trans. Graph.   36, 4 (2017). J. Yu and S. LaValle. 2013. Multi-agent path planning and network flow. In   Algorithmic Foundations of Robotics X . Springer, 157‚Äì173. J. Zehnder, S. Coros, and B. Thomaszewski. 2016. Designing structurally-sound orna- mental curve networks.   ACM Trans. Graph.   35, 4 (2016), 99. Y. Zhu, R. Bridson, and D. Kaufman. 2018. Blended cured quasi-newton for distortion optimization.   ACM Trans. Graph.   37, 4 (2018), 1‚Äì14. A   SOBOLEV-SLOBODECKIJ GRADIENT How do we obtain an ideal gradient flow for the tangent-point energy ( i.e. , one that behaves like an ODE)? Unlike standard energies (elastic energy, Willmore energy,   etc. ), an answer to this question has not yet been worked out formally. However, we can make an educated guess based on past wisdom about curve energies. In general, suppose an energy   ‚Ñ∞   has a (Fr√©chet) differential   d ‚Ñ∞ . To determine the highest-order derivatives, it is not necessary to derive an explicit expression for   d ‚Ñ∞   as we did for the Dirichlet energy (Section 4.1). Instead, we can reason about the associated function spaces: as long as we know the   order   of   d ‚Ñ∞ , we can ‚Äúcancel‚Äù spatial derivatives by constructing an inner product of the same order. For the tangent-point energy, existing analysis gives the maxi- mum order of derivatives in   ‚Ñ∞ Œ± Œ≤   (Appendix A.2), from which we deduce the order of   d ‚Ñ∞ Œ± Œ≤   (Appendix A.3). What is unusual here is that the number of derivatives is   fractional   (Appendix A.1.2); to build an inner product of appropriate order, we therefore start with the   fractional Laplacian   (Section A.1), and formulate an analogous operator for embedded curves. Taking further (integer) derivatives then yields an operator of the same order as   d ‚Ñ∞ Œ± Œ≤   (Appendix A.4). From there, we use additional heuristics (inspired by numerical experiments) to choose a low-order term that makes this operator well-behaved and invertible (Appendix A.4.2), allowing us to use it in the definition of a fractional Sobolev gradient (Section 4.2). A.1   Fractional Analysis We begin with a brief discussion of Sobolev spaces of   fractional order   k   <   Z ; for further background, see [Di Nezza et al. 2012]. ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 18 ===
XX:18   ‚Ä¢   Yu, Schumacher, and Crane Fig. 34. Fractional Laplacian of   f   for several values of   œÉ   . A.1.1   Fractional Differential Opera- tors.   Whereas standard differential op- erators   L   are purely   local   ( i.e. , the value of   ( Lu )( x )   depends only on an arbitrar- ily small neighborhood of   u ( x ) ), frac- tional differential operators are   nonlo- cal   ( ( Lu )( x )   can depend on the value of   u   at any point   y ). Since the tangent- point energy is nonlocal, it will also have nonlocal derivatives. Hence, find- ing an inner product well-matched to its gradient flow entails constructing an appropriate fractional differential operator‚Äîan important ex- ample in our setting is the   fractional Laplacian   (‚àí ‚àÜ ) œÉ   on   R n   , which is commonly defined by taking powers of the eigenvalues in the spectral expansion. For   œÉ   ‚àà ( 0 ,   1 )   and all sufficiently regular u ,   v   :   R n   ‚Üí   R , the operator can also be expressed via the integral ‚ü®‚ü®(‚àí ‚àÜ ) œÉ   u ,   v ‚ü©‚ü©   =   C ‚à¨ R n   √ó R n u ( x )‚àí u ( y ) | x   ‚àí   y | œÉ v ( x )‚àí v ( y ) | x   ‚àí   y | œÉ dxd y | x   ‚àí   y | n   ,   (24) where the constant   C   ‚àà   R   depends only on   n   and   œÉ   [Kwa≈õnicki 2017]. The behavior of this operator is illustrated in Figure 34. A.1.2   Fractional Sobolev Spaces.   There are two common ways to understand Sobolev spaces of fractional order. One is to consider the Fourier transform of the Laplacian   ‚àÜ , leading to the   Bessel potential spaces   H s , p   : =   (‚àí ‚àÜ ) ‚àí s / 2 ( L p   )   [Triebel 1983, Section 2.2.2]. For us, however, this viewpoint helps only to understand the case   W   s , 2 . The other, essential for studying the tangent-point energy, is via the   Sobolev-Slobodeckij spaces   W   k + œÉ   , p   . Functions   u   in these spaces look like functions in an ordinary Sobolev space, but with a non- local regularity condition on the highest-order derivative   u ( k ) . In particular, suppose we write   s   =   k   +   œÉ   for   k   ‚àà   Z ‚â• 0   and   œÉ   ‚àà ( 0 ,   1 ) . Then, on an   n -dimensional Riemannian manifold   M , one defines W   k + œÉ   , p   ( M )   : =    u   ‚àà   W   k   , p   ( M )   [ u ( k ) ] W   œÉ   , p   <   ‚àû   . The expression in square brackets is the (Gagliardo) semi-norm [ u ] W   œÉ   , p   : =  ‚à¨ M   2 u ( x )‚àí u ( y ) d ( x ,   y ) œÉ p   dx d y d ( x ,   y ) n  1 / p , where   d ( x ,   y )   is the shortest distance between   x   and   y   in   M . Just as a Lipschitz function is more regular than an arbitrary continu- ous function without being differentiable, a function in   W   k + œÉ   , p   is more regular than one in   W   k   , p   , without getting a whole additional derivative ( i.e. ,   W   k + 1 , p   ‚ää   W   k + œÉ   , p   ). Figure 35 shows an example. Fig. 35. The curves   ( x   ,   | x   | œÉ   )   are examples of curves in   W   œÉ   , p   (left) . Their 1st derivatives are not   L p   integrable   (right) . Dual Space.   Just as the dual of the classical Sobolev space   W   k   , p is   W   ‚àí k   , q   (where   1 / p   +   1 / q   =   1 ), the dual of the Sobolev-Solobdeckij space   W   s , p   can be characterized as a space with ‚Äú ‚àí s   derivatives‚Äù in the sense that the fractional Laplacian   (‚àí ‚àÜ ) s   identifies   W   s , p   with W   ‚àí s , q   : =   ( W   s , p   ) ‚àó   [Di Nezza et al. 2012, Remark 2.5]. A.2   Energy Space To determine the order of the tangent-point differential   d ‚Ñ∞ Œ± Œ≤   , we first consider the biggest space of functions for which the energy ‚Ñ∞ Œ± Œ≤   is well-defined. Blatt [2013] gives the following condition on the differentiability of the curve   Œ≥   (see also Blatt and Reiter [2015]): Lemma A.1.   Suppose   Œ±   >   1   and   Œ≤   ‚àà [ Œ±   +   2 ,   2   Œ±   +   1 ) , let   s   B   Œ≤ Œ±   ‚àí   1 Œ±   , and consider an embedded curve   Œ≥   ‚àà   C 1 ( S 1 ;   R 3 ) . Then   Œ≥   has finite tangent point energy   ‚Ñ∞ Œ± Œ≤   ( Œ≥   )   if and only if, up to reparameterization, Œ≥   ‚àà   W   s , Œ±   ( S 1 ;   R 3 ) . In other words, the tangent point energy is well-defined only for curves that have an   s th derivative, and for which the   Œ± th power of that derivative is integrable‚Äîfor example, it will not be finite for a polygonal curve. The somewhat unusual situation is that   s   is not an integer: instead, it is a fractional value in the interval   ( 1 ,   2 ) . A.3   Order of the Differential In general, if an energy   ‚Ñ∞   is defined for functions in a space   X   , then its differential   d ‚Ñ∞ Œ± Œ≤   will have the prototype   d ‚Ñ∞   :   X   ‚Üí   X   ‚àó , where   X   ‚àó   is the dual space. For instance, the Dirichlet energy   ‚Ñ∞ D operates only on functions   f   ‚àà   H   1 . Hence, its differential is a map d ‚Ñ∞ D   :   H   1   ‚Üí ( H   1 ) ‚àó , which we saw explicitly in Section 4.1: given a function   f   ‚àà   H   1 ,   d ‚Ñ∞ D   | f   produces a linear map   ‚ü®‚ü®‚àí ‚àÜ f   ,   ¬∑‚ü©‚ü©   from functions in   H   1   to real numbers,   i.e. , an element of   ( H   1 ) ‚àó . In the case of the tangent point energy, then, we get that   d ‚Ñ∞ Œ± Œ≤   is a map from   W   s , p   to the dual space   ( W   s , p   ) ‚àó   =   W   ‚àí s , q   (Section A.1.1). Hence,   d ‚Ñ∞ Œ± Œ≤   is a ‚Äúdifferential operator‚Äù of order   2 s ,   i.e. , it reduces the differentiability of its argument by   2 s . To get a well-behaved flow, we should therefore pick an inner product of the same order, and (for computational purposes) is reasonably easy to invert. A.4   Fractional Inner Product Just as Sobolev inner products are defined via   ‚àÜ , we use a fractional operator to define a fractional Sobolev inner product. For an embed- ded curve   Œ≥   :   M   ‚Üí   R 3 , one idea is to use the 1D fractional Laplacian (‚àí ‚àÜ ) œÉ   . Instead, we define an analogous operator by replacing the intrinsic distance   | x   ‚àí   y |   in Equation 24 with the extrinsic distance | Œ≥   ( x ) ‚àí   Œ≥   ( y )| , yielding an operator   L œÉ   defined by ‚ü®‚ü® L œÉ   u ,   v ‚ü©‚ü©   : = ‚à¨ M   2 u ( x )‚àí u ( y ) | Œ≥   ( x )‚àí Œ≥   ( y )| œÉ v ( x )‚àí v ( y ) | Œ≥   ( x )‚àí Œ≥   ( y )| œÉ dx Œ≥   d y Œ≥ | Œ≥   ( x )‚àí Œ≥   ( y )|   (25) for all sufficiently regular   u ,   v   :   M   ‚Üí   R . For any   œÉ   ‚àà ( 0 ,   1 ) , both (‚àí ‚àÜ ) œÉ   and   L œÉ   are fractional operators of order   2 œÉ   . But the benefit of L œÉ   is that it requires only Euclidean distances‚Äîwhich for embedded curves are easier to evaluate than geodesic distances. Moreover, building a fractional Laplacian via an explicit Fourier transform is prohibitively expensive, requiring a full eigendecomposition of a dis- crete Laplace matrix. In contrast, integral expressions like Equations 24 and 25 can easily be evaluated   √† la   Section 5.2.3, and accelerated using hierarchical techniques   √† la   Section 6. ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 19 ===
Repulsive Curves   ‚Ä¢   XX:19 A.4.1   High-Order Term.   To get an inner product of the same order as   d ‚Ñ∞ Œ± Œ≤   , we compose the operator   L œÉ   with further (integer) deriva- tives   ùíü . In particular, Lemma A.1 implies that   s   =   1 + œÉ   for   œÉ   ‚àà ( 0 ,   1 ) . Hence, to define an operator   B œÉ   of order   2 s   =   2 œÉ   +   2 , we apply two additional derivatives to   L œÉ   ,   i.e. , we say that ‚ü®‚ü® B œÉ   u ,   v ‚ü©‚ü©   : =   ‚ü®‚ü® L œÉ   ùíü u ,   ùíü v ‚ü©‚ü© for all sufficiently regular   u ,   v   :   M   ‚Üí   R . This relationship provides the definition of   B œÉ   in Equation 12. A.4.2   Low-Order Term.   As discussed in Section 4.2.2,   B œÉ   is not invertible. We hence add the low-order term   B 0 œÉ   from Equation 13. Since   B œÉ   and   B 0 œÉ   exhibit the same scaling under a rescaling of   Œ≥   , the flow behavior will not depend on the global scale. To see why, consider scaling   Œ≥   by a factor   c   >   0 . Then   ùíü   scales by a factor 1 / c , the term   1 /| Œ≥   ( x ) ‚àí   Œ≥   ( y )| 2 s + 1   scales by   1 / c 2 s + 1 , and the measure dx Œ≥   d y Œ≥   scales by   c 2 . Then   B œÉ   scales by   c 2 /( c 2 c 2 s + 1 )   =   1 / c 2 s + 1 ,   and L œÉ   scales by just   c 2 / c 2 s + 1 . Hence, to get   B 0 œÉ   we multiply   L œÉ   by   k 2 4   , which scales like   1 / c 2 . More generally, one could use   k Œ± Œ≤   for any   Œ± ,   Œ≤ such that   Œ±   ‚àí   Œ≤   =   ‚àí 2 . This low-order term also tends to accelerate the evolution of the flow by preserving near-constant motions that slide near-tangentially and do not tend toward collision (Figure 7). B   ACCELERATION SCHEME B.1   Energy and Differential Evaluation B.1.1   Bounding Volume Hierarchy.   Let   p I   : =   ( T I   ,   x I   ) ‚àà   R 6   for each edge   I   ‚àà   E . To build the BVH we cycle through all six coordinates, and split by minimizing the sum of squared diameters of the two child bounding boxes. Below a user-specified threshold, all remain- ing tangent-points are placed in a single leaf node. In each node   ùí© we also store data needed for Barnes-Hut. Specifically, L ùí©   : = √ï I   ‚àà ùí© ‚Ñì I   ,   x ùí©   : = √ï I   ‚àà ùí© ‚Ñì I   x I   / L ùí©   ,   T   ùí©   : = √ï I   ‚àà ùí© ‚Ñì I   T I   / L ùí©   , give the total mass, center of mass, and (length-weighted) average tangent,   resp. ; we will use   p ùí©   : =   ( T   ùí©   ,   x ùí©   )   to denote the corre- sponding tangent-point. We also store the bounding box radii   r   ùí© x and   r   ùí© T   with respect to spatial and tangential coordinates,   resp. B.1.2   Barnes-Hut Approximation.   To evaluate the energy for a tangent-point   p I   =   ( T I   ,   x I   ) ‚àà   R 6   with mass   ‚Ñì I   ‚àà   R , we traverse the BVH from the root, checking at each node if a local approxima- tion is   admissable   (see below). If so, we evaluate the approximation ( ‚Ñ∞ Œ± Œ≤   ) I   ‚Ñ¨   : =   | T I   √ó ( x I   ‚àí   x ‚Ñ¨ )| Œ± | x I   ‚àí   x ‚Ñ¨   | Œ≤   ‚Ñì I   L ‚Ñ¨   .   (26) and terminate traversal; otherwise, we sum the energy of the two children. If we reach a leaf node   ‚Ñ¨ , we directly add up the contribu- tions of the edges contained in this node,   i.e. , √ï J   ‚àà ‚Ñ¨ | T I   √ó ( x I   ‚àí   x   J   )| Œ± | x I   ‚àí   x   J   | Œ≤   ‚Ñì I   ‚Ñì J   . Admissibility.   A simple Taylor series analysis of Equation 26 in- dicates that to keep approximation error below a user-specified threshold   Œµ   >   0 , it is sufficient to ensure that r   ‚Ñ¨ x   /| x I   ‚àí   x ‚Ñ¨   |   ‚â≤   Œµ   and   r   ‚Ñ¨ T   ‚â≤   Œµ .   (27) Intuitively, if   ‚Ñ¨   is far from   p I   relative to its size,   and   contains tan- gents that are close together, then the ‚Äúlumped‚Äù energy is a good approximation of the total energy between   I   and edges in   ‚Ñ¨ . Differential.   Rather than differentiate our Barnes-Hut approxi- mation of   ÀÜ ‚Ñ∞ Œ± Œ≤   , we approximate the differential of the (full) discrete energy directly. Starting with the zero vector   d   ÀÜ ‚Ñ∞ Œ± Œ≤   =   0   ‚àà   R 3 | V   |   , we perform a BVH traversal for the tangent point   p I   associated with each edge   I   ‚àà   E . At each admissible node   ‚Ñ¨   and for each endpoint i a   ,   a   =   1 ,   2   of   I   we increment the differential via ( d   ÀÜ ‚Ñ∞ Œ± Œ≤   ) i a   + =   L ‚Ñ¨   ‚àÇ ‚àÇ Œ≥ ia  ‚Ñì I   (   ÀÜ k Œ± Œ≤   ( x I   ,   x ‚Ñ¨ , T I   )   +   ÀÜ k Œ± Œ≤   ( x ‚Ñ¨ ,   x I   , T   ‚Ñ¨ ))  . The kernel   ÀÜ k Œ± Œ≤   is defined in Equation 18; note that   L ‚Ñ¨ ,   x ‚Ñ¨ , and   T   ‚Ñ¨   do not depend on   Œ≥ i 1   or   Œ≥ i 2   , since   I   is not contained in any admissible node   ‚Ñ¨ . At any leaf   ‚Ñ¨   we add the derivatives for all edges   J   ‚àà   ‚Ñ¨ . B.2   Hierarchical Matrix-Vector Product B.2.1   Block Cluster Tree (BCT).   A BCT partitions a matrix into low-rank   blocks   that approximate the original entries (Figure 12). It is like a quadtree, except that the matrix ordering is not fixed   a priori . The basic idea is that the edges in a BVH node   ùí©   correspond to a subset of BCT rows/columns. A block of the BCT is hence specified by a pair of nodes   ( ùíú ,   ‚Ñ¨ )   from the BVH. To construct a BCT, we recursively split the root block   ( ‚Ñõ ,   ‚Ñõ ) , where   ‚Ñõ   is the root of the BVH. A block   ( ùíú ,   ‚Ñ¨ )   is a leaf if and only if (i) it is   well-separated ,   i.e. , it provides a good approximation of the local double sum, or (ii)   ùíú or   ‚Ñ¨   contains just a few edges. Otherwise, this block is given four children   ( ùíú 1 ,   ‚Ñ¨ 1 ) ,   ( ùíú 1 ,   ‚Ñ¨ 2 ) ,   ( ùíú 2 ,   ‚Ñ¨ 1 ) ,   ( ùíú 2 ,   ‚Ñ¨ 2 ) , where   ùíú 1 ,   ùíú 2   are the children of   ùíú   in the BVH (and likewise for   ‚Ñ¨ ). The conditions for being well-separated are similar to Equation 27: max ( r   ùíú x   ,   r   ‚Ñ¨ x   ) | x ùíú   ‚àí   x ‚Ñ¨   |   ‚â≤   Œµ   and   max ( r   ùíú T   ,   r   ‚Ñ¨ T   )   ‚â≤   Œµ ,   (28) where   r   ùí© x   and   r   ùí© T   are the spatial and tangential radii of node   ùí©   . B.2.2   Matrix-Vector Product.   The BCT is used to accelerate matrix- vector products   œÜ   =   K œà   via a 0th-order   fast multipole method ‚Äîwhich is accurate enough for preconditioning. For any admissible leaf node ( ùíú ,   ‚Ñ¨ ) , the midpoints and tangents of edges in   ùíú   and   ‚Ñ¨   are coherent relative to the distance between them. The restriction of   K   to rows I   ‚àà   ùíú   and columns   J   ‚àà   ‚Ñ¨   is hence well-approximated by b K ùíú‚Ñ¨   : =   ‚Ñì [ ùíú ]   k ( p ùíú ,   p ‚Ñ¨ )   ‚Ñì [ ‚Ñ¨ ] T , where   ‚Ñì [ ùí©   ] ‚àà   R | ùí©   |   is the vector of edge lengths in   ùí©   . Using this rank-1 approximation, matrix-vector multiplication amounts to a single dot product (with   ‚Ñì [ ‚Ñ¨ ] ), followed by a scalar-vector product. To perform a multiplication, we start with the zero vector   œÜ   = 0   ‚àà   R | E   |   and iterate over all BCT leaves. For each admissible leaf ( ùíú ,   ‚Ñ¨ )   ( i.e. , one which satisfies Equation 28) we perform an update œÜ [ ùíú ] ‚Üê   œÜ [ ùíú ]   +   b K ùíú‚Ñ¨   œà   [ ‚Ñ¨ ] . For inadmissible leaves, we simply sum over all edge pairs: œÜ I   ‚Üê   œÜ I   + √ï J   ‚àà ‚Ñ¨ K I   J   œà J for all   I   ‚àà   ùíú . To accelerate evaluation, we percolate these sums up and down the BVH, following a standard fast multipole strategy. ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.

=== PAGE 20 ===
XX:20   ‚Ä¢   Yu, Schumacher, and Crane B.3   Multigrid Solver We first sketch out a generic multigrid strategy for saddle-point problems on a curve network; the specific solves needed for the tangent-point energy are detailed in Appendix B.3.4. B.3.1   Geometric Multigrid.   Suppose we want to solve a linear equa- tion   Ax   =   b . The basic idea of geometric multigrid is to use a coarser mesh to reduce the residual of an equation on the finer mesh. Con- sider a simple two-level hierarchy‚Äîin particular, let   A 0   ‚àà   R | V 0   |√ó| V 0   | and   A 1   ‚àà   R | V 1   |√ó| V 1   |   be discretizations of   A   on a fine and coarse mesh,   resp. , and let   b 0   be a discretization of the function   b   onto the finest mesh. Also let   J 1   ‚àà   R | V 0   |√ó| V 1   |   be a so-called   prolongation operator , which interpolates data from the coarse mesh onto the fine mesh. Starting with any initial guess   x 0   ‚àà   R | V 0   |   , we first apply a smoothing procedure   S   to the system   A 0 x 0   =   b 0 ,   i.e. , a fixed number of iterations of any iterative linear solver to get an improved guess Àú x 0   ‚Üê   S ( A 0 ,   x 0 ,   b 0 ) . We then compute the residual   r 0   ‚Üê   A 0   Àú x 0   ‚àí   b 0 , and transfer it to the coarse mesh via   b 1   ‚Üê   J T 1   r 0 . On the coarse mesh we solve the system   A 1 x 1   =   b 1   directly, and transfer the result back to the fine mesh via   y 0   ‚Üê   J 1 x 1 . These values are used to update our guess via   Àú x 0   ‚Üê   Àú x 0   +   y 0 , and smoothed again. If the residual is small enough, we stop; otherwise, we repeat another such   V-cycle   until convergence. More generally, one can apply this two-level strategy to solve the linear system on the coarser level, yielding a multi-level strategy. The size of the coarsest level is chosen so that a direct solve at this level is more efficient than continuing to apply multigrid. Initialization.   We get an initial guess   x 0   by first coarsening the fine right-hand side   b 0   down to the coarsest mesh. We then perform a direct solve and prolong the solution all the way to the finest mesh, applying smoothing after each refinement. In practice this strategy works much better than starting with the zero vector. Implementation Details.   In practice we use a standard conjugate gradient smoother, and typically need 6 or fewer V-cycles to achieve a relative residual of order   10 ‚àí 3 . Making the residual smaller via further cycles (and a more accurate BCT) yields diminishing returns: we need only a reasonable intermediate descent direction. Note that although we build a BCT at each level, overall construction cost is only about twice the cost at the finest level. B.3.2   Curve Coarsening and Prolongation.   To build a multigrid hierarchy on a curve net- work, we apply a simple coarsening scheme. We mark alternating vertices as ‚Äúblack‚Äù and ‚Äúwhite‚Äù, and mark all endpoints and junctures where two or more curves meet as black. The next coarsest curve is obtained by removing white vertices; we stop when we reach a target size or when there are no more white nodes. The prolongation operator   J   preserves values at black vertices, and at white vertices takes the average of the two neighboring black vertices. In our experience, using linear interpolation based on edge lengths did not improve multigrid performance. Coarsening need not preserve the isotopy class of the curve network to provide useful preconditioning for the next level of the hierarchy. B.3.3   Multigrid for Saddle Point Problems.   Our constraint scheme entails solving   saddle point problems   of the form    A   C T C   0     x Œª  =    a 0  ,   (29) where   A   is the inner product (for vector-valued functions) (see Equation 19), and   C   is the constraint matrix (Section 5.3.1); the data   a   ‚àà   R 3 | V   |   depends on the problem being solved. We follow the approach of Braess and Sarazin [1997], who note that for the structurally identical   Stokes‚Äô problem   (where   A   and   C   are replaced by the Laplace and divergence operators,   resp. ), applying multigrid to the whole matrix does not work well. Instead, let   P   ‚àà   R 3 | V   |√ó 3 | V   | be a projection onto the null space of   C ,   i.e. ,   CP   =   0   and   P 2   =   P . Then by construction, any solution   y   to the equation P T APy   =   P T a   (30) yields a vector   x   =   Py   within the constraint space   Cx   =   0   that satis- fies our original equation. Equation 30 is therefore the system that we actually solve via multigrid. In particular, we use the projection P   : =   CC ‚Ä† , where   ‚Ä†   denotes the (Moore-Penrose) pseudoinverse C ‚Ä†   : =   ( CC T ) ‚àí 1 C T . Since our constraints are typically sparse, we can factorize the inner term   CC T   (once per time step) to further accelerate computation. Note that one must build a constraint matrix   C i   and projection matrix   P i   at each level   i   of the multigrid hierarchy. B.3.4   Gradient Solve and Constraint Projection.   With these pieces in place, we can apply multigrid to compute the constrained gradient (Equation 22), and perform constraint projection (Equation 23). Gradient.   To compute the gradient, recall that   A   =   B 0 + B . A matrix- vector product   B 0 u   can be expressed as B 0 u   =   E T ( diag ( K 1 ) ‚àí   K ) Eu   (31) where   diag ( v )   is a diagonal matrix with entries   v ,   E   ‚àà   R | E   |√ó| V   | averages values from vertices to edges ( i.e. ,   ( Eu ) I   =   1 2   ( u i 1 + u i 2   ) ), and K I   J   =   ( k 2 2 œÉ   + 5 ( x I   ,   x   J   , T I   )   +   k 2 2 œÉ   + 5 ( x   J   ,   x I   , T J   )) ‚Ñì I   ‚Ñì J   .   (32) We use the method from Appendix B.2 to efficiently perform the products   K 1   and   B 0 u , and ordinary sparse matrix multiplication for   E . The high-order part   B   is expressed exactly as in Equation 31, except that (i) we replace the averaging operator   E   with the dif- ference operator   D , (ii) we define a different kernel matrix   K   by replacing   k 2 2 œÉ   + 5   with   k 0 2 œÉ   + 1   in Equation 32, and (iii) just like   A , K   acts blockwise on the three components of vector-valued data x   ‚àà   R 3 | E   |   ( √† la   Equation 19). Constraint Projection.   To use our multigrid solver for constraint projection, we apply a simple transformation to Equation 23 that gives it the same form as Equation 29. In particular, we solve    A   C T C   0     y Œº  =    Az 0  , where   z   : =   C ‚Ä† b , and   b   is the lower block of the right-hand side of Equation 23. The final result is then given by x   =   z   ‚àí   y .   (33) ACM Trans. Graph., Vol. X, No. X, Article XX. Publication date: XXXX.
